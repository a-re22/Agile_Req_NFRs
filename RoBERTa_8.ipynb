{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyN2MYfni1o+VpRtcmFeyFmm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"fb8d69c6729b4b0d9fe35d460ec0f4aa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d74e45109380406397434bc18fecc15a","IPY_MODEL_571d7fd8f3ac4a45b836506a511f4cdf","IPY_MODEL_3f65629e2aec491a80958ea201007777"],"layout":"IPY_MODEL_2b6f038357ab40aeb44e07d084907de4"}},"d74e45109380406397434bc18fecc15a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_202c451298564c98a59ec3bbdbfab022","placeholder":"​","style":"IPY_MODEL_68508bc952114c958fbfc300bdfeb7c9","value":"tokenizer_config.json: 100%"}},"571d7fd8f3ac4a45b836506a511f4cdf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_213f3f8808114d63853fd3fd31211291","max":25,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6fa029248dcf4887b70bb87fb4da08c5","value":25}},"3f65629e2aec491a80958ea201007777":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f9bdbe6301db4522aae1ced8ff54b317","placeholder":"​","style":"IPY_MODEL_f0652139642147c29b33ceea3dea5855","value":" 25.0/25.0 [00:00&lt;00:00, 1.90kB/s]"}},"2b6f038357ab40aeb44e07d084907de4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"202c451298564c98a59ec3bbdbfab022":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68508bc952114c958fbfc300bdfeb7c9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"213f3f8808114d63853fd3fd31211291":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6fa029248dcf4887b70bb87fb4da08c5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f9bdbe6301db4522aae1ced8ff54b317":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0652139642147c29b33ceea3dea5855":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d6a824d051e84422ad9303f39229d5d1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3a4581b7faca465081d7ed103f927634","IPY_MODEL_774a9459ce384e51bc67472bca7c6ee7","IPY_MODEL_7d0140466002415e8997bbb42a1e9401"],"layout":"IPY_MODEL_120e5ff9c3444e7ba1020ed623184bba"}},"3a4581b7faca465081d7ed103f927634":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea39b99925c544c1a15893bc2968be7b","placeholder":"​","style":"IPY_MODEL_df65dabb089a47efa629f2303ddd3fec","value":"vocab.json: 100%"}},"774a9459ce384e51bc67472bca7c6ee7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e05bf702f9f4c7397bec7215e763077","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e432145c2a1c47cc9a3e267ad2e66d54","value":898823}},"7d0140466002415e8997bbb42a1e9401":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9cbba94a4a14c29b3d9b7fd3c7e91c8","placeholder":"​","style":"IPY_MODEL_f4661c8131b240e582d27fe6a8d34621","value":" 899k/899k [00:00&lt;00:00, 4.98MB/s]"}},"120e5ff9c3444e7ba1020ed623184bba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea39b99925c544c1a15893bc2968be7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df65dabb089a47efa629f2303ddd3fec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e05bf702f9f4c7397bec7215e763077":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e432145c2a1c47cc9a3e267ad2e66d54":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b9cbba94a4a14c29b3d9b7fd3c7e91c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4661c8131b240e582d27fe6a8d34621":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6df4304bcccc4a6fa3502008db943caf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dfeeffaedc81437a8b57f663a37f6269","IPY_MODEL_5feda8123117444aa3f9bf7f88a12de9","IPY_MODEL_3830469dd9c24c7ea282ad8a9e2136ca"],"layout":"IPY_MODEL_2b83cb97334b4466a33241964385cb66"}},"dfeeffaedc81437a8b57f663a37f6269":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f520d77f1a904f4c97e0e0208d5d1873","placeholder":"​","style":"IPY_MODEL_47b5bd0713bb4f73b601d1c161f6c566","value":"merges.txt: 100%"}},"5feda8123117444aa3f9bf7f88a12de9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e257138250e4254a31639ab4c50a499","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cd1a645e7415483c9fdacf12a49fed1b","value":456318}},"3830469dd9c24c7ea282ad8a9e2136ca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f1e14364946c471aaed845a653b3ffa4","placeholder":"​","style":"IPY_MODEL_cc8c2302911847f091ff586929828660","value":" 456k/456k [00:00&lt;00:00, 3.71MB/s]"}},"2b83cb97334b4466a33241964385cb66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f520d77f1a904f4c97e0e0208d5d1873":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47b5bd0713bb4f73b601d1c161f6c566":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0e257138250e4254a31639ab4c50a499":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd1a645e7415483c9fdacf12a49fed1b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f1e14364946c471aaed845a653b3ffa4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc8c2302911847f091ff586929828660":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9cc4ace1dd2548e19ab273df603499ff":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d0ffdf25a03844b6b18d4dcd97228dd9","IPY_MODEL_7906d4c266f344eab3d4897bc327d222","IPY_MODEL_6088f7565b9b4167a75d7cf09d65e3a5"],"layout":"IPY_MODEL_9f17eac8d529493a9451ac01538f23dd"}},"d0ffdf25a03844b6b18d4dcd97228dd9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f23cd4d2f7246fbbccaa03097ee81b1","placeholder":"​","style":"IPY_MODEL_0ce00c8881794f9b939ebf78dc609a5a","value":"tokenizer.json: 100%"}},"7906d4c266f344eab3d4897bc327d222":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_791bb09abf374d7895e4607a36b90486","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a095a96e716141b08c1d8a385b6b3b8c","value":1355863}},"6088f7565b9b4167a75d7cf09d65e3a5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_43a4436502fe4f7688de4cc9a56c86ea","placeholder":"​","style":"IPY_MODEL_53c0170ec7f9473ba77a9c38bde9edd7","value":" 1.36M/1.36M [00:00&lt;00:00, 7.24MB/s]"}},"9f17eac8d529493a9451ac01538f23dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f23cd4d2f7246fbbccaa03097ee81b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ce00c8881794f9b939ebf78dc609a5a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"791bb09abf374d7895e4607a36b90486":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a095a96e716141b08c1d8a385b6b3b8c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"43a4436502fe4f7688de4cc9a56c86ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53c0170ec7f9473ba77a9c38bde9edd7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ab6df703acb7438c958e40d5eaffa680":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ede159a0292b44b0ae8843e19a33c9cf","IPY_MODEL_5a7da45b8c5a46ccabb018911af20c44","IPY_MODEL_aa57dcbd53c345df9085a5560ee46eaa"],"layout":"IPY_MODEL_4c93a44da9c14f3099b7fbed3e22e215"}},"ede159a0292b44b0ae8843e19a33c9cf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce007468c0884f738f82cfb4bb30b7ca","placeholder":"​","style":"IPY_MODEL_20603eecbb7b443ea5fd7e3e8f7bc412","value":"config.json: 100%"}},"5a7da45b8c5a46ccabb018911af20c44":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2908c09262aa41beb7d80a71a18cbcc2","max":481,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2e2d18c6c22343a08ef16c4c0faef985","value":481}},"aa57dcbd53c345df9085a5560ee46eaa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f760d53cb72f4fd3be401fc56daa46e4","placeholder":"​","style":"IPY_MODEL_2a84be5a73434b87a65698dae30d9b9b","value":" 481/481 [00:00&lt;00:00, 42.7kB/s]"}},"4c93a44da9c14f3099b7fbed3e22e215":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce007468c0884f738f82cfb4bb30b7ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20603eecbb7b443ea5fd7e3e8f7bc412":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2908c09262aa41beb7d80a71a18cbcc2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e2d18c6c22343a08ef16c4c0faef985":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f760d53cb72f4fd3be401fc56daa46e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a84be5a73434b87a65698dae30d9b9b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"69c01654ec6646638a041a00239f370e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6bdc078ffb9d43c3b4f2d252cd17b7d5","IPY_MODEL_930ce745e8fe459d93fab1eb81798d14","IPY_MODEL_c06cb02c958341d38ec04136c6ecb370"],"layout":"IPY_MODEL_b9bf94f755224d03ba7ef8bd3c0da657"}},"6bdc078ffb9d43c3b4f2d252cd17b7d5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b5adffd677f4da28a34206527739119","placeholder":"​","style":"IPY_MODEL_78dda07e8eff4deca54ace2709fcac00","value":"model.safetensors: 100%"}},"930ce745e8fe459d93fab1eb81798d14":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_29383bce2b294dca9367c54ea43cec56","max":498818054,"min":0,"orientation":"horizontal","style":"IPY_MODEL_44729a27784246e6a346bbe380540e61","value":498818054}},"c06cb02c958341d38ec04136c6ecb370":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd610e53ff1540ca8d028fc46be4c3c8","placeholder":"​","style":"IPY_MODEL_2701f530f13e4010ae2116a8ff5221c7","value":" 499M/499M [00:02&lt;00:00, 242MB/s]"}},"b9bf94f755224d03ba7ef8bd3c0da657":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b5adffd677f4da28a34206527739119":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78dda07e8eff4deca54ace2709fcac00":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"29383bce2b294dca9367c54ea43cec56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44729a27784246e6a346bbe380540e61":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bd610e53ff1540ca8d028fc46be4c3c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2701f530f13e4010ae2116a8ff5221c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"0ZVYVaVvq5nl","executionInfo":{"status":"ok","timestamp":1739843192703,"user_tz":-180,"elapsed":19865,"user":{"displayName":"Abdulrahim Alhaizaey","userId":"15189532503014553776"}}},"outputs":[],"source":["import os\n","import csv\n","import pandas as pd\n","import torch\n","import re\n","import nltk\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, matthews_corrcoef\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from transformers import Trainer, TrainingArguments, EarlyStoppingCallback, RobertaTokenizer, RobertaForSequenceClassification\n","import torch.nn as nn\n","import wandb\n","\n","from google.colab import auth\n","from google.colab import drive\n","from google.colab import userdata"]},{"cell_type":"code","source":["# =========================\n","# STEP 0: mount to drive\n","# =========================\n","#auth.authenticate_user()\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HmxkvZpnrfzJ","executionInfo":{"status":"ok","timestamp":1739843225885,"user_tz":-180,"elapsed":33186,"user":{"displayName":"Abdulrahim Alhaizaey","userId":"15189532503014553776"}},"outputId":"e0fe4ae4-1bc5-43b0-c0c7-22cbe9d2366c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# =========================\n","# STEP 1: Initialize WandB\n","# =========================\n","# Retrieve API Key from Colab Secrets\n","wandb_api_key = userdata.get('WANDB_API_KEY')\n","\n","if wandb_api_key:\n","    os.environ[\"WANDB_API_KEY\"] = wandb_api_key\n","    wandb.login(key=wandb_api_key)\n","    print(\"✅ WandB Logged in Securely\")\n","else:\n","    print(\"❌ Error: WANDB_API_KEY not found. Set it in Colab Secrets.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-AwRCuPvrf2V","executionInfo":{"status":"ok","timestamp":1739843232503,"user_tz":-180,"elapsed":6623,"user":{"displayName":"Abdulrahim Alhaizaey","userId":"15189532503014553776"}},"outputId":"96eeb79d-ace7-4d6d-ffc3-e87f525ffe58"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maalhaizaey\u001b[0m (\u001b[33mabdulrahim-alhaizaey\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"stream","name":"stdout","text":["✅ WandB Logged in Securely\n"]}]},{"cell_type":"code","source":["# =========================\n","# STEP 2: LOAD DATA & CLEAN TEXT\n","# =========================\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","\n","multi_data = pd.read_csv(\"/content/10006_dataset_Multi.csv\", encoding='ISO-8859-1')\n","\n","def clean_text(text):\n","    if pd.isnull(text):\n","        return \"\"\n","    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text).lower()\n","    return text\n","\n","multi_data['cleaned_text'] = multi_data['text'].apply(clean_text)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jRqDN6Vrrf5Z","executionInfo":{"status":"ok","timestamp":1739843235881,"user_tz":-180,"elapsed":313,"user":{"displayName":"Abdulrahim Alhaizaey","userId":"15189532503014553776"}},"outputId":"b5970182-6b0d-4d91-99bd-8b72c39c9832"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]}]},{"cell_type":"code","source":["# =========================\n","# STEP 3: PREPARE DATASETS & LABEL ENCODING (Train Only)\n","# =========================\n","multi_train, multi_val = train_test_split(multi_data, test_size=0.2, stratify=multi_data['label'], random_state=42)\n","\n","# Fit LabelEncoder only on training data to prevent leakage\n","multi_le = LabelEncoder()\n","multi_le.fit(multi_train['label'])\n","multi_train['encoded_label'] = multi_le.transform(multi_train['label'])\n","multi_val['encoded_label'] = multi_le.transform(multi_val['label'])\n"],"metadata":{"id":"GDFrKPRsrf8e","executionInfo":{"status":"ok","timestamp":1739843238462,"user_tz":-180,"elapsed":365,"user":{"displayName":"Abdulrahim Alhaizaey","userId":"15189532503014553776"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# =========================\n","# STEP 4: TOKENIZATION (Train Data Only for max_length)\n","# =========================\n","tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n","\n","# Calculate max_length using training data\n","max_length = min(tokenizer.model_max_length, max(multi_train['cleaned_text'].apply(lambda x: len(tokenizer.tokenize(x)))))\n","print(f\"Using max_length from training set only: {max_length}\")\n","\n","def tokenize_data(df, label_col):\n","    encodings = tokenizer(df['cleaned_text'].tolist(), truncation=True, padding=True, max_length=max_length, return_tensors=\"pt\")\n","    labels = torch.tensor(df[label_col].tolist())\n","    return encodings, labels\n","\n","train_multi_enc, train_multi_labels = tokenize_data(multi_train, 'encoded_label')\n","val_multi_enc, val_multi_labels = tokenize_data(multi_val, 'encoded_label')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":316,"referenced_widgets":["fb8d69c6729b4b0d9fe35d460ec0f4aa","d74e45109380406397434bc18fecc15a","571d7fd8f3ac4a45b836506a511f4cdf","3f65629e2aec491a80958ea201007777","2b6f038357ab40aeb44e07d084907de4","202c451298564c98a59ec3bbdbfab022","68508bc952114c958fbfc300bdfeb7c9","213f3f8808114d63853fd3fd31211291","6fa029248dcf4887b70bb87fb4da08c5","f9bdbe6301db4522aae1ced8ff54b317","f0652139642147c29b33ceea3dea5855","d6a824d051e84422ad9303f39229d5d1","3a4581b7faca465081d7ed103f927634","774a9459ce384e51bc67472bca7c6ee7","7d0140466002415e8997bbb42a1e9401","120e5ff9c3444e7ba1020ed623184bba","ea39b99925c544c1a15893bc2968be7b","df65dabb089a47efa629f2303ddd3fec","3e05bf702f9f4c7397bec7215e763077","e432145c2a1c47cc9a3e267ad2e66d54","b9cbba94a4a14c29b3d9b7fd3c7e91c8","f4661c8131b240e582d27fe6a8d34621","6df4304bcccc4a6fa3502008db943caf","dfeeffaedc81437a8b57f663a37f6269","5feda8123117444aa3f9bf7f88a12de9","3830469dd9c24c7ea282ad8a9e2136ca","2b83cb97334b4466a33241964385cb66","f520d77f1a904f4c97e0e0208d5d1873","47b5bd0713bb4f73b601d1c161f6c566","0e257138250e4254a31639ab4c50a499","cd1a645e7415483c9fdacf12a49fed1b","f1e14364946c471aaed845a653b3ffa4","cc8c2302911847f091ff586929828660","9cc4ace1dd2548e19ab273df603499ff","d0ffdf25a03844b6b18d4dcd97228dd9","7906d4c266f344eab3d4897bc327d222","6088f7565b9b4167a75d7cf09d65e3a5","9f17eac8d529493a9451ac01538f23dd","0f23cd4d2f7246fbbccaa03097ee81b1","0ce00c8881794f9b939ebf78dc609a5a","791bb09abf374d7895e4607a36b90486","a095a96e716141b08c1d8a385b6b3b8c","43a4436502fe4f7688de4cc9a56c86ea","53c0170ec7f9473ba77a9c38bde9edd7","ab6df703acb7438c958e40d5eaffa680","ede159a0292b44b0ae8843e19a33c9cf","5a7da45b8c5a46ccabb018911af20c44","aa57dcbd53c345df9085a5560ee46eaa","4c93a44da9c14f3099b7fbed3e22e215","ce007468c0884f738f82cfb4bb30b7ca","20603eecbb7b443ea5fd7e3e8f7bc412","2908c09262aa41beb7d80a71a18cbcc2","2e2d18c6c22343a08ef16c4c0faef985","f760d53cb72f4fd3be401fc56daa46e4","2a84be5a73434b87a65698dae30d9b9b"]},"id":"2SxUgwe4rf_T","executionInfo":{"status":"ok","timestamp":1739843247205,"user_tz":-180,"elapsed":7419,"user":{"displayName":"Abdulrahim Alhaizaey","userId":"15189532503014553776"}},"outputId":"07bce320-14fb-4d9f-9a37-d2080c832fa6"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb8d69c6729b4b0d9fe35d460ec0f4aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6a824d051e84422ad9303f39229d5d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6df4304bcccc4a6fa3502008db943caf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9cc4ace1dd2548e19ab273df603499ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab6df703acb7438c958e40d5eaffa680"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Using max_length from training set only: 116\n"]}]},{"cell_type":"code","source":["# =========================\n","# STEP 5: DATASET CLASS & METRICS\n","# =========================\n","class TextDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        item = {key: val[idx] for key, val in self.encodings.items()}\n","        item['labels'] = self.labels[idx]\n","        return item\n","\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=1)\n","    accuracy = accuracy_score(labels, predictions)\n","    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted', zero_division=0)\n","    mcc = matthews_corrcoef(labels, predictions)\n","    return {\n","        \"accuracy\": accuracy,\n","        \"precision\": precision,\n","        \"recall\": recall,\n","        \"f1\": f1,\n","        \"mcc\": mcc\n","    }\n"],"metadata":{"id":"j_9YgmAMrgCY","executionInfo":{"status":"ok","timestamp":1739843254434,"user_tz":-180,"elapsed":348,"user":{"displayName":"Abdulrahim Alhaizaey","userId":"15189532503014553776"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# =========================\n","# STEP 6: FOCAL LOSS & CUSTOM TRAINER\n","# =========================\n","class FocalLoss(nn.Module):\n","    def __init__(self, alpha=0.25, gamma=2.0, reduction='mean'):\n","        super().__init__()\n","        self.alpha = alpha\n","        self.gamma = gamma\n","        self.reduction = reduction\n","\n","    def forward(self, inputs, targets):\n","        ce_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n","        pt = torch.exp(-ce_loss)\n","        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n","        return focal_loss.mean() if self.reduction == 'mean' else focal_loss.sum()\n","\n","class CustomTrainer(Trainer):\n","    def __init__(self, *args, **kwargs):\n","        super().__init__(*args, **kwargs)\n","        self.training_loss = []\n","        self.validation_loss = []\n","        self.results = []\n","\n","    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n","        labels = inputs.pop(\"labels\")\n","        outputs = model(**inputs)\n","        logits = outputs.logits\n","        loss_fn = FocalLoss(alpha=0.25, gamma=2.0)\n","        loss = loss_fn(logits, labels)\n","        return (loss, outputs) if return_outputs else loss\n","\n","    def evaluate(self, *args, **kwargs):\n","        output = super().evaluate(*args, **kwargs)\n","        self.validation_loss.append(output['eval_loss'])\n","        self.results.append(output.copy())\n","        return output\n","\n","    def log(self, logs, *args, **kwargs):\n","        super().log(logs, *args, **kwargs)\n","        if 'loss' in logs:\n","            self.training_loss.append(logs['loss'])\n"],"metadata":{"id":"zZOhUkSnrgFY","executionInfo":{"status":"ok","timestamp":1739843267152,"user_tz":-180,"elapsed":412,"user":{"displayName":"Abdulrahim Alhaizaey","userId":"15189532503014553776"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# =========================\n","# STEP 7: ADD PLOTTING (Confusion Matrices & Loss Curves)\n","# =========================\n","def plot_confusion_matrix(labels, predictions, label_encoder, output_dir, run_name):\n","    class_names = label_encoder.classes_\n","    conf_matrix = confusion_matrix(labels, predictions)\n","    plt.figure(figsize=(8, 6))\n","    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n","    plt.xlabel('Predicted')\n","    plt.ylabel('Actual')\n","    plt.savefig(f\"{output_dir}/{run_name}_confusion_numbers.png\")\n","    plt.close()\n","\n","def plot_confusion_matrix_percent(labels, predictions, label_encoder, output_dir, run_name):\n","    class_names = label_encoder.classes_\n","    conf_matrix = confusion_matrix(labels, predictions, normalize='true')\n","    plt.figure(figsize=(8, 6))\n","    sns.heatmap(conf_matrix, annot=True, fmt='.2f', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n","    plt.xlabel('Predicted')\n","    plt.ylabel('Actual')\n","    plt.savefig(f\"{output_dir}/{run_name}_confusion_percent.png\")\n","    plt.close()\n","\n","def plot_confusion_matrix_class_weighted(labels, predictions, label_encoder, output_dir, run_name):\n","    conf_matrix = confusion_matrix(labels, predictions, normalize='true')\n","    plt.figure(figsize=(8, 6))\n","    sns.heatmap(conf_matrix, annot=True, fmt='.2f', cmap='coolwarm', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n","    plt.xlabel('Predicted')\n","    plt.ylabel('Actual')\n","    plt.savefig(f\"{output_dir}/{run_name}_confusion_weighted.png\")\n","    plt.close()\n","\n","def plot_loss(training_loss, validation_loss, output_dir, run_name):\n","    min_length = min(len(training_loss), len(validation_loss))\n","    training_loss = training_loss[:min_length]\n","    validation_loss = validation_loss[:min_length]\n","    epochs = range(1, min_length + 1)\n","    plt.figure(figsize=(8, 6))\n","    plt.plot(epochs, training_loss, label='Training Loss', marker='o')\n","    plt.plot(epochs, validation_loss, label='Validation Loss', marker='s', linestyle='--')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.grid(True)\n","    plt.savefig(f\"{output_dir}/{run_name}_loss_curves.png\")\n","    plt.close()\n"],"metadata":{"id":"YanyQwuyrgIu","executionInfo":{"status":"ok","timestamp":1739843270028,"user_tz":-180,"elapsed":480,"user":{"displayName":"Abdulrahim Alhaizaey","userId":"15189532503014553776"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# =========================\n","# STEP 8: TRAIN FUNCTION\n","# =========================\n","def train_roberta(train_dataset, eval_dataset, num_labels, output_dir, label_encoder, config=None):\n","    with wandb.init(config=config):\n","        config = wandb.config\n","        run_name = wandb.run.name\n","\n","        base_dir = \"/content/drive/MyDrive/RoBERTa_8_Results\"\n","        run_dir = os.path.join(base_dir, run_name)\n","        os.makedirs(run_dir, exist_ok=True)\n","\n","        model = RobertaForSequenceClassification.from_pretrained(\n","            \"roberta-base\",\n","            num_labels=num_labels,\n","            hidden_dropout_prob=config.dropout,\n","            attention_probs_dropout_prob=config.dropout\n","        )\n","\n","        num_devices = torch.cuda.device_count()  # Will be 1 on Colab\n","        examples_per_step = config.batch_size * num_devices * config.gradient_accumulation_steps\n","        total_steps = int(np.ceil(len(train_dataset) / examples_per_step) * config.num_train_epochs)\n","\n","        warmup_steps = int(0.1 * total_steps)\n","        print(f\"Total Steps: {total_steps}, Warmup Steps (10%): {warmup_steps}\")\n","\n","        training_args = TrainingArguments(\n","            output_dir=output_dir,\n","            run_name=run_name,\n","            num_train_epochs=config.num_train_epochs,\n","            per_device_train_batch_size=config.batch_size,\n","            per_device_eval_batch_size=config.batch_size,\n","            learning_rate=config.learning_rate,\n","            warmup_steps=warmup_steps,\n","            weight_decay=config.weight_decay,\n","            evaluation_strategy=\"epoch\",\n","            logging_strategy=\"epoch\",\n","            save_strategy=\"epoch\",\n","            fp16=True,\n","            gradient_checkpointing=True,\n","            save_total_limit=2,\n","            gradient_accumulation_steps=config.gradient_accumulation_steps,\n","            max_grad_norm=config.max_grad_norm,\n","            lr_scheduler_type=\"cosine_with_restarts\",\n","            load_best_model_at_end=True,\n","            metric_for_best_model=\"eval_loss\",\n","            report_to=\"wandb\"\n","        )\n","\n","        trainer = CustomTrainer(\n","            model=model,\n","            args=training_args,\n","            train_dataset=train_dataset,\n","            eval_dataset=eval_dataset,\n","            compute_metrics=compute_metrics,\n","            callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n","        )\n","\n","        trainer.train()\n","\n","        # Save Best Model\n","        best_model_path = os.path.join(run_dir, \"best_model\")\n","        trainer.save_model(best_model_path)\n","        print(f\"✅ Best model saved to {best_model_path}\")\n","\n","        # Evaluate Best Model\n","        results = trainer.evaluate(eval_dataset=eval_dataset)\n","\n","        predictions_obj = trainer.predict(eval_dataset)\n","        predictions = np.argmax(predictions_obj.predictions, axis=1)\n","        labels = predictions_obj.label_ids\n","\n","        wandb.log({\n","            \"eval_loss\": results.get(\"eval_loss\"),\n","            \"eval_accuracy\": results.get(\"eval_accuracy\"),\n","            \"eval_precision\": results.get(\"eval_precision\"),\n","            \"eval_recall\": results.get(\"eval_recall\"),\n","            \"eval_f1\": results.get(\"eval_f1\"),\n","            \"eval_mcc\": results.get(\"eval_mcc\")\n","        })\n","\n","        plot_confusion_matrix(labels, predictions, label_encoder, run_dir, run_name)\n","        plot_confusion_matrix_percent(labels, predictions, label_encoder, run_dir, run_name)\n","        plot_confusion_matrix_class_weighted(labels, predictions, label_encoder, run_dir, run_name)\n","        plot_loss(trainer.training_loss, trainer.validation_loss, run_dir, run_name)\n","\n","        # Save run parameters and results to a CSV file\n","        results_csv = os.path.join(run_dir, \"results.csv\")\n","        with open(results_csv, mode='w', newline='') as file:\n","            writer = csv.writer(file)\n","            writer.writerow([\"Parameter\", \"Value\"])\n","            for key, value in config.items():\n","                writer.writerow([key, value])\n","            writer.writerow([\"Epoch\", \"Training Loss\", \"Validation Loss\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"Mcc\"])\n","            for epoch, result in enumerate(trainer.results, start=1):\n","                writer.writerow([\n","                    epoch,\n","                    trainer.training_loss[epoch - 1] if epoch - 1 < len(trainer.training_loss) else None,\n","                    trainer.validation_loss[epoch - 1] if epoch - 1 < len(trainer.validation_loss) else None,\n","                    result.get(\"eval_accuracy\"),\n","                    result.get(\"eval_precision\"),\n","                    result.get(\"eval_recall\"),\n","                    result.get(\"eval_f1\"),\n","                    result.get(\"eval_mcc\")\n","                ])\n","\n","        return results"],"metadata":{"id":"HTyQhJRrsUn0","executionInfo":{"status":"ok","timestamp":1739843271453,"user_tz":-180,"elapsed":2,"user":{"displayName":"Abdulrahim Alhaizaey","userId":"15189532503014553776"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# =========================\n","# STEP 9: RUN SWEEP CONFIGURATION\n","# =========================\n","train_dataset = TextDataset(train_multi_enc, train_multi_labels)\n","val_dataset = TextDataset(val_multi_enc, val_multi_labels)\n","\n","sweep_config = {\n","    'method': 'bayes',\n","    'metric': {'name': 'eval_loss', 'goal': 'minimize'},\n","    'parameters': {\n","        'num_train_epochs': {'values': [12]},\n","        'learning_rate': {'min': 1e-5, 'max': 5e-5},\n","        'batch_size': {'values': [8, 16, 32]},\n","        'weight_decay': {'min': 0.01, 'max': 0.05},\n","        'dropout': {'min': 0.05, 'max': 0.5},\n","        'gradient_accumulation_steps': {'values': [2, 4]},\n","        'max_grad_norm': {'values': [1.0, 2.0]}\n","    },\n","}"],"metadata":{"id":"QtzdwszQsUun","executionInfo":{"status":"ok","timestamp":1739843273422,"user_tz":-180,"elapsed":324,"user":{"displayName":"Abdulrahim Alhaizaey","userId":"15189532503014553776"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["sweep_id = wandb.sweep(sweep=sweep_config, project='RoBERTa_8')\n","\n","wandb.agent(sweep_id, function=lambda: train_roberta(\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    num_labels=len(multi_le.classes_),\n","    output_dir=\"multi_output\",\n","    label_encoder=multi_le\n","))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["69c01654ec6646638a041a00239f370e","6bdc078ffb9d43c3b4f2d252cd17b7d5","930ce745e8fe459d93fab1eb81798d14","c06cb02c958341d38ec04136c6ecb370","b9bf94f755224d03ba7ef8bd3c0da657","7b5adffd677f4da28a34206527739119","78dda07e8eff4deca54ace2709fcac00","29383bce2b294dca9367c54ea43cec56","44729a27784246e6a346bbe380540e61","bd610e53ff1540ca8d028fc46be4c3c8","2701f530f13e4010ae2116a8ff5221c7"]},"id":"8XeDvRlPrgMW","executionInfo":{"status":"ok","timestamp":1739848300750,"user_tz":-180,"elapsed":5025762,"user":{"displayName":"Abdulrahim Alhaizaey","userId":"15189532503014553776"}},"outputId":"3a9c6d29-8862-408c-eecd-dfc1163d0af8"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Create sweep with ID: 4tf3f9z8\n","Sweep URL: https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: f2r1tbsy with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4874726431101276\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.861988928598048e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_grad_norm: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 12\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.01112759556651764\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.6"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250218_014756-f2r1tbsy</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/f2r1tbsy' target=\"_blank\">confused-sweep-1</a></strong> to <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/f2r1tbsy' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/f2r1tbsy</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69c01654ec6646638a041a00239f370e"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Total Steps: 756, Warmup Steps (10%): 75\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_grad_norm' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_train_epochs' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='744' max='744' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [744/744 03:48, Epoch 11/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Mcc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.345600</td>\n","      <td>0.264829</td>\n","      <td>0.645355</td>\n","      <td>0.416483</td>\n","      <td>0.645355</td>\n","      <td>0.506253</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.237800</td>\n","      <td>0.224523</td>\n","      <td>0.645355</td>\n","      <td>0.416483</td>\n","      <td>0.645355</td>\n","      <td>0.506253</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.235300</td>\n","      <td>0.221883</td>\n","      <td>0.645355</td>\n","      <td>0.416483</td>\n","      <td>0.645355</td>\n","      <td>0.506253</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.234200</td>\n","      <td>0.222444</td>\n","      <td>0.645355</td>\n","      <td>0.416483</td>\n","      <td>0.645355</td>\n","      <td>0.506253</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.232600</td>\n","      <td>0.220326</td>\n","      <td>0.645355</td>\n","      <td>0.416483</td>\n","      <td>0.645355</td>\n","      <td>0.506253</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.230400</td>\n","      <td>0.220149</td>\n","      <td>0.645355</td>\n","      <td>0.416483</td>\n","      <td>0.645355</td>\n","      <td>0.506253</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.231700</td>\n","      <td>0.222572</td>\n","      <td>0.645355</td>\n","      <td>0.416483</td>\n","      <td>0.645355</td>\n","      <td>0.506253</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.230600</td>\n","      <td>0.219711</td>\n","      <td>0.645355</td>\n","      <td>0.416483</td>\n","      <td>0.645355</td>\n","      <td>0.506253</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.231500</td>\n","      <td>0.219173</td>\n","      <td>0.645355</td>\n","      <td>0.416483</td>\n","      <td>0.645355</td>\n","      <td>0.506253</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.230200</td>\n","      <td>0.219086</td>\n","      <td>0.645355</td>\n","      <td>0.416483</td>\n","      <td>0.645355</td>\n","      <td>0.506253</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.234200</td>\n","      <td>0.219089</td>\n","      <td>0.645355</td>\n","      <td>0.416483</td>\n","      <td>0.645355</td>\n","      <td>0.506253</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ Best model saved to /content/drive/MyDrive/RoBERTa_8_Results/confused-sweep-1/best_model\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/f1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/loss</td><td>█▂▁▂▁▁▂▁▁▁▁▁▁</td></tr><tr><td>eval/mcc</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/precision</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/recall</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>█▂▅▆▄▃▄▁▂▃▄▅▅</td></tr><tr><td>eval/samples_per_second</td><td>▁▇▃▃▅▆▅█▇▆▅▄▄</td></tr><tr><td>eval/steps_per_second</td><td>▁▇▃▃▅▆▅█▇▆▅▄▄</td></tr><tr><td>eval_accuracy</td><td>▁</td></tr><tr><td>eval_f1</td><td>▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_mcc</td><td>▁</td></tr><tr><td>eval_precision</td><td>▁</td></tr><tr><td>eval_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/mcc</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▂▃▃▄▄▄▄▅▅▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▂▃▃▄▄▄▄▅▅▆▆▆▆▇▇▇▇██████</td></tr><tr><td>train/grad_norm</td><td>▇▄█▃▃▂▁▁▂▃▆▂</td></tr><tr><td>train/learning_rate</td><td>▇██▇▆▅▄▃▂▂▁▁</td></tr><tr><td>train/loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.64535</td></tr><tr><td>eval/f1</td><td>0.50625</td></tr><tr><td>eval/loss</td><td>0.21909</td></tr><tr><td>eval/mcc</td><td>0</td></tr><tr><td>eval/precision</td><td>0.41648</td></tr><tr><td>eval/recall</td><td>0.64535</td></tr><tr><td>eval/runtime</td><td>0.8904</td></tr><tr><td>eval/samples_per_second</td><td>2248.368</td></tr><tr><td>eval/steps_per_second</td><td>70.753</td></tr><tr><td>eval_accuracy</td><td>0.64535</td></tr><tr><td>eval_f1</td><td>0.50625</td></tr><tr><td>eval_loss</td><td>0.21909</td></tr><tr><td>eval_mcc</td><td>0</td></tr><tr><td>eval_precision</td><td>0.41648</td></tr><tr><td>eval_recall</td><td>0.64535</td></tr><tr><td>test/accuracy</td><td>0.64535</td></tr><tr><td>test/f1</td><td>0.50625</td></tr><tr><td>test/loss</td><td>0.21909</td></tr><tr><td>test/mcc</td><td>0</td></tr><tr><td>test/precision</td><td>0.41648</td></tr><tr><td>test/recall</td><td>0.64535</td></tr><tr><td>test/runtime</td><td>0.9647</td></tr><tr><td>test/samples_per_second</td><td>2075.238</td></tr><tr><td>test/steps_per_second</td><td>65.305</td></tr><tr><td>total_flos</td><td>5637844508675328.0</td></tr><tr><td>train/epoch</td><td>11.81275</td></tr><tr><td>train/global_step</td><td>744</td></tr><tr><td>train/grad_norm</td><td>14.35063</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.2342</td></tr><tr><td>train_loss</td><td>0.24226</td></tr><tr><td>train_runtime</td><td>229.9763</td></tr><tr><td>train_samples_per_second</td><td>417.643</td></tr><tr><td>train_steps_per_second</td><td>3.235</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">confused-sweep-1</strong> at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/f2r1tbsy' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/f2r1tbsy</a><br> View project at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250218_014756-f2r1tbsy/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4r46xzfr with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.21352309758911348\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3.2356003877876264e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_grad_norm: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 12\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.047554053961837886\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.6"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250218_015201-4r46xzfr</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/4r46xzfr' target=\"_blank\">super-sweep-2</a></strong> to <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/4r46xzfr' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/4r46xzfr</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Total Steps: 3012, Warmup Steps (10%): 301\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_grad_norm' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_train_epochs' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2259' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2259/3000 05:28 < 01:47, 6.88 it/s, Epoch 9/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Mcc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.204100</td>\n","      <td>0.057743</td>\n","      <td>0.853646</td>\n","      <td>0.862788</td>\n","      <td>0.853646</td>\n","      <td>0.852123</td>\n","      <td>0.741175</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.057700</td>\n","      <td>0.054059</td>\n","      <td>0.817682</td>\n","      <td>0.863459</td>\n","      <td>0.817682</td>\n","      <td>0.829187</td>\n","      <td>0.722522</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.037200</td>\n","      <td>0.047118</td>\n","      <td>0.872128</td>\n","      <td>0.887061</td>\n","      <td>0.872128</td>\n","      <td>0.875814</td>\n","      <td>0.789628</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.026700</td>\n","      <td>0.046342</td>\n","      <td>0.869630</td>\n","      <td>0.891009</td>\n","      <td>0.869630</td>\n","      <td>0.874829</td>\n","      <td>0.788087</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.019800</td>\n","      <td>0.050244</td>\n","      <td>0.872627</td>\n","      <td>0.892130</td>\n","      <td>0.872627</td>\n","      <td>0.878112</td>\n","      <td>0.791509</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.014200</td>\n","      <td>0.041325</td>\n","      <td>0.891109</td>\n","      <td>0.903606</td>\n","      <td>0.891109</td>\n","      <td>0.894515</td>\n","      <td>0.819343</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.009900</td>\n","      <td>0.046290</td>\n","      <td>0.890609</td>\n","      <td>0.904783</td>\n","      <td>0.890609</td>\n","      <td>0.894250</td>\n","      <td>0.821093</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.007400</td>\n","      <td>0.051196</td>\n","      <td>0.861139</td>\n","      <td>0.892171</td>\n","      <td>0.861139</td>\n","      <td>0.869045</td>\n","      <td>0.782993</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.005100</td>\n","      <td>0.042876</td>\n","      <td>0.898102</td>\n","      <td>0.911556</td>\n","      <td>0.898102</td>\n","      <td>0.901471</td>\n","      <td>0.831290</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ Best model saved to /content/drive/MyDrive/RoBERTa_8_Results/super-sweep-2/best_model\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▄▁▆▆▆▇▇▅█▇</td></tr><tr><td>eval/f1</td><td>▃▁▆▅▆▇▇▅█▇</td></tr><tr><td>eval/loss</td><td>█▆▃▃▅▁▃▅▂▁</td></tr><tr><td>eval/mcc</td><td>▂▁▅▅▅▇▇▅█▇</td></tr><tr><td>eval/precision</td><td>▁▁▄▅▅▇▇▅█▇</td></tr><tr><td>eval/recall</td><td>▄▁▆▆▆▇▇▅█▇</td></tr><tr><td>eval/runtime</td><td>▆▃▁▅▃▄▅█▇█</td></tr><tr><td>eval/samples_per_second</td><td>▃▆█▄▆▅▄▁▂▁</td></tr><tr><td>eval/steps_per_second</td><td>▃▆█▄▆▅▄▁▂▁</td></tr><tr><td>eval_accuracy</td><td>▁</td></tr><tr><td>eval_f1</td><td>▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_mcc</td><td>▁</td></tr><tr><td>eval_precision</td><td>▁</td></tr><tr><td>eval_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/mcc</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▄▄▅▅▅▅▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▄▄▅▅▅▅▆▆▇▇██████</td></tr><tr><td>train/grad_norm</td><td>█▄▅▁▁▂▁▁▂</td></tr><tr><td>train/learning_rate</td><td>▇██▇▆▅▃▂▁</td></tr><tr><td>train/loss</td><td>█▃▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.89111</td></tr><tr><td>eval/f1</td><td>0.89451</td></tr><tr><td>eval/loss</td><td>0.04132</td></tr><tr><td>eval/mcc</td><td>0.81934</td></tr><tr><td>eval/precision</td><td>0.90361</td></tr><tr><td>eval/recall</td><td>0.89111</td></tr><tr><td>eval/runtime</td><td>1.7437</td></tr><tr><td>eval/samples_per_second</td><td>1148.142</td></tr><tr><td>eval/steps_per_second</td><td>72.261</td></tr><tr><td>eval_accuracy</td><td>0.89111</td></tr><tr><td>eval_f1</td><td>0.89451</td></tr><tr><td>eval_loss</td><td>0.04132</td></tr><tr><td>eval_mcc</td><td>0.81934</td></tr><tr><td>eval_precision</td><td>0.90361</td></tr><tr><td>eval_recall</td><td>0.89111</td></tr><tr><td>test/accuracy</td><td>0.89111</td></tr><tr><td>test/f1</td><td>0.89451</td></tr><tr><td>test/loss</td><td>0.04132</td></tr><tr><td>test/mcc</td><td>0.81934</td></tr><tr><td>test/precision</td><td>0.90361</td></tr><tr><td>test/recall</td><td>0.89111</td></tr><tr><td>test/runtime</td><td>1.9103</td></tr><tr><td>test/samples_per_second</td><td>1047.986</td></tr><tr><td>test/steps_per_second</td><td>65.957</td></tr><tr><td>total_flos</td><td>4294376422481664.0</td></tr><tr><td>train/epoch</td><td>9</td></tr><tr><td>train/global_step</td><td>2259</td></tr><tr><td>train/grad_norm</td><td>0.71101</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.0051</td></tr><tr><td>train_loss</td><td>0.04246</td></tr><tr><td>train_runtime</td><td>328.3533</td></tr><tr><td>train_samples_per_second</td><td>292.514</td></tr><tr><td>train_steps_per_second</td><td>9.137</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">super-sweep-2</strong> at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/4r46xzfr' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/4r46xzfr</a><br> View project at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250218_015201-4r46xzfr/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9m6paod8 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2175502282911708\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2.905518888539008e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_grad_norm: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 12\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.028971344201183406\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.6"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250218_015746-9m6paod8</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/9m6paod8' target=\"_blank\">hopeful-sweep-3</a></strong> to <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/9m6paod8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/9m6paod8</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Total Steps: 756, Warmup Steps (10%): 75\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_grad_norm' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_train_epochs' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='630' max='744' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [630/744 03:12 < 00:34, 3.27 it/s, Epoch 10/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Mcc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.281500</td>\n","      <td>0.169851</td>\n","      <td>0.707792</td>\n","      <td>0.598620</td>\n","      <td>0.707792</td>\n","      <td>0.636623</td>\n","      <td>0.392693</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.111900</td>\n","      <td>0.081356</td>\n","      <td>0.768731</td>\n","      <td>0.834308</td>\n","      <td>0.768731</td>\n","      <td>0.784322</td>\n","      <td>0.657441</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.047500</td>\n","      <td>0.060236</td>\n","      <td>0.821678</td>\n","      <td>0.860774</td>\n","      <td>0.821678</td>\n","      <td>0.831722</td>\n","      <td>0.725337</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.032800</td>\n","      <td>0.042308</td>\n","      <td>0.881119</td>\n","      <td>0.894224</td>\n","      <td>0.881119</td>\n","      <td>0.882804</td>\n","      <td>0.796346</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.025900</td>\n","      <td>0.056273</td>\n","      <td>0.837662</td>\n","      <td>0.880188</td>\n","      <td>0.837662</td>\n","      <td>0.848867</td>\n","      <td>0.747108</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.020100</td>\n","      <td>0.054509</td>\n","      <td>0.843656</td>\n","      <td>0.883729</td>\n","      <td>0.843656</td>\n","      <td>0.853002</td>\n","      <td>0.763194</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.017100</td>\n","      <td>0.040957</td>\n","      <td>0.887612</td>\n","      <td>0.899670</td>\n","      <td>0.887612</td>\n","      <td>0.891030</td>\n","      <td>0.813430</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.013600</td>\n","      <td>0.047153</td>\n","      <td>0.868132</td>\n","      <td>0.891862</td>\n","      <td>0.868132</td>\n","      <td>0.874618</td>\n","      <td>0.789697</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.011900</td>\n","      <td>0.044368</td>\n","      <td>0.871628</td>\n","      <td>0.890653</td>\n","      <td>0.871628</td>\n","      <td>0.876761</td>\n","      <td>0.792099</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.010800</td>\n","      <td>0.043069</td>\n","      <td>0.878621</td>\n","      <td>0.896143</td>\n","      <td>0.878621</td>\n","      <td>0.883565</td>\n","      <td>0.802113</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ Best model saved to /content/drive/MyDrive/RoBERTa_8_Results/hopeful-sweep-3/best_model\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▃▅█▆▆█▇▇██</td></tr><tr><td>eval/f1</td><td>▁▅▆█▇▇█████</td></tr><tr><td>eval/loss</td><td>█▃▂▁▂▂▁▁▁▁▁</td></tr><tr><td>eval/mcc</td><td>▁▅▇█▇▇█████</td></tr><tr><td>eval/precision</td><td>▁▆▇████████</td></tr><tr><td>eval/recall</td><td>▁▃▅█▆▆█▇▇██</td></tr><tr><td>eval/runtime</td><td>▇▁▆▂█▆▆▅▃▆▆</td></tr><tr><td>eval/samples_per_second</td><td>▂█▃▇▁▃▃▄▆▃▃</td></tr><tr><td>eval/steps_per_second</td><td>▂█▃▇▁▃▃▄▆▃▃</td></tr><tr><td>eval_accuracy</td><td>▁</td></tr><tr><td>eval_f1</td><td>▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_mcc</td><td>▁</td></tr><tr><td>eval_precision</td><td>▁</td></tr><tr><td>eval_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/mcc</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇██████</td></tr><tr><td>train/grad_norm</td><td>▇██▄▂▄▄▁▄▅</td></tr><tr><td>train/learning_rate</td><td>▇██▇▆▅▄▃▂▁</td></tr><tr><td>train/loss</td><td>█▄▂▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.88761</td></tr><tr><td>eval/f1</td><td>0.89103</td></tr><tr><td>eval/loss</td><td>0.04096</td></tr><tr><td>eval/mcc</td><td>0.81343</td></tr><tr><td>eval/precision</td><td>0.89967</td></tr><tr><td>eval/recall</td><td>0.88761</td></tr><tr><td>eval/runtime</td><td>0.8962</td></tr><tr><td>eval/samples_per_second</td><td>2233.964</td></tr><tr><td>eval/steps_per_second</td><td>70.3</td></tr><tr><td>eval_accuracy</td><td>0.88761</td></tr><tr><td>eval_f1</td><td>0.89103</td></tr><tr><td>eval_loss</td><td>0.04096</td></tr><tr><td>eval_mcc</td><td>0.81343</td></tr><tr><td>eval_precision</td><td>0.89967</td></tr><tr><td>eval_recall</td><td>0.88761</td></tr><tr><td>test/accuracy</td><td>0.88761</td></tr><tr><td>test/f1</td><td>0.89103</td></tr><tr><td>test/loss</td><td>0.04096</td></tr><tr><td>test/mcc</td><td>0.81343</td></tr><tr><td>test/precision</td><td>0.89967</td></tr><tr><td>test/recall</td><td>0.88761</td></tr><tr><td>test/runtime</td><td>0.9877</td></tr><tr><td>test/samples_per_second</td><td>2026.975</td></tr><tr><td>test/steps_per_second</td><td>63.786</td></tr><tr><td>total_flos</td><td>4771529358312960.0</td></tr><tr><td>train/epoch</td><td>10</td></tr><tr><td>train/global_step</td><td>630</td></tr><tr><td>train/grad_norm</td><td>1.34266</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0108</td></tr><tr><td>train_loss</td><td>0.05731</td></tr><tr><td>train_runtime</td><td>192.3475</td></tr><tr><td>train_samples_per_second</td><td>499.346</td></tr><tr><td>train_steps_per_second</td><td>3.868</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">hopeful-sweep-3</strong> at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/9m6paod8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/9m6paod8</a><br> View project at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250218_015746-9m6paod8/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 43dvpkkr with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4589825587391758\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2.8643818851441172e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_grad_norm: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 12\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.010424727931810847\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.6"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250218_020109-43dvpkkr</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/43dvpkkr' target=\"_blank\">elated-sweep-4</a></strong> to <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/43dvpkkr' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/43dvpkkr</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Total Steps: 3012, Warmup Steps (10%): 301\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_grad_norm' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_train_epochs' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1004' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1004/3000 04:28 < 08:55, 3.73 it/s, Epoch 4/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Mcc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.299500</td>\n","      <td>0.222952</td>\n","      <td>0.645355</td>\n","      <td>0.416483</td>\n","      <td>0.645355</td>\n","      <td>0.506253</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.235100</td>\n","      <td>0.259586</td>\n","      <td>0.645355</td>\n","      <td>0.416483</td>\n","      <td>0.645355</td>\n","      <td>0.506253</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.235800</td>\n","      <td>0.254056</td>\n","      <td>0.645355</td>\n","      <td>0.416483</td>\n","      <td>0.645355</td>\n","      <td>0.506253</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.232600</td>\n","      <td>0.262732</td>\n","      <td>0.645355</td>\n","      <td>0.416483</td>\n","      <td>0.645355</td>\n","      <td>0.506253</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ Best model saved to /content/drive/MyDrive/RoBERTa_8_Results/elated-sweep-4/best_model\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▁▁▁▁</td></tr><tr><td>eval/f1</td><td>▁▁▁▁▁</td></tr><tr><td>eval/loss</td><td>▁▇▆█▁</td></tr><tr><td>eval/mcc</td><td>▁▁▁▁▁</td></tr><tr><td>eval/precision</td><td>▁▁▁▁▁</td></tr><tr><td>eval/recall</td><td>▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▁█▄▇▅</td></tr><tr><td>eval/samples_per_second</td><td>█▁▅▂▃</td></tr><tr><td>eval/steps_per_second</td><td>█▁▅▂▃</td></tr><tr><td>eval_accuracy</td><td>▁</td></tr><tr><td>eval_f1</td><td>▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_mcc</td><td>▁</td></tr><tr><td>eval_precision</td><td>▁</td></tr><tr><td>eval_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/mcc</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▆▆██████</td></tr><tr><td>train/grad_norm</td><td>█▂▁▁</td></tr><tr><td>train/learning_rate</td><td>▁█▆▂</td></tr><tr><td>train/loss</td><td>█▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.64535</td></tr><tr><td>eval/f1</td><td>0.50625</td></tr><tr><td>eval/loss</td><td>0.22295</td></tr><tr><td>eval/mcc</td><td>0</td></tr><tr><td>eval/precision</td><td>0.41648</td></tr><tr><td>eval/recall</td><td>0.64535</td></tr><tr><td>eval/runtime</td><td>3.4464</td></tr><tr><td>eval/samples_per_second</td><td>580.889</td></tr><tr><td>eval/steps_per_second</td><td>72.829</td></tr><tr><td>eval_accuracy</td><td>0.64535</td></tr><tr><td>eval_f1</td><td>0.50625</td></tr><tr><td>eval_loss</td><td>0.22295</td></tr><tr><td>eval_mcc</td><td>0</td></tr><tr><td>eval_precision</td><td>0.41648</td></tr><tr><td>eval_recall</td><td>0.64535</td></tr><tr><td>test/accuracy</td><td>0.64535</td></tr><tr><td>test/f1</td><td>0.50625</td></tr><tr><td>test/loss</td><td>0.22295</td></tr><tr><td>test/mcc</td><td>0</td></tr><tr><td>test/precision</td><td>0.41648</td></tr><tr><td>test/recall</td><td>0.64535</td></tr><tr><td>test/runtime</td><td>3.9954</td></tr><tr><td>test/samples_per_second</td><td>501.082</td></tr><tr><td>test/steps_per_second</td><td>62.823</td></tr><tr><td>total_flos</td><td>1908611743325184.0</td></tr><tr><td>train/epoch</td><td>4</td></tr><tr><td>train/global_step</td><td>1004</td></tr><tr><td>train/grad_norm</td><td>1.23284</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>0.2326</td></tr><tr><td>train_loss</td><td>0.25076</td></tr><tr><td>train_runtime</td><td>269.1034</td></tr><tr><td>train_samples_per_second</td><td>356.919</td></tr><tr><td>train_steps_per_second</td><td>11.148</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">elated-sweep-4</strong> at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/43dvpkkr' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/43dvpkkr</a><br> View project at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250218_020109-43dvpkkr/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kad96j3k with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1607683269385195\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 4.2438274772048047e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_grad_norm: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 12\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.04152759415158302\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.6"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250218_020557-kad96j3k</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/kad96j3k' target=\"_blank\">glowing-sweep-5</a></strong> to <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/kad96j3k' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/kad96j3k</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Total Steps: 756, Warmup Steps (10%): 75\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_grad_norm' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_train_epochs' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='441' max='744' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [441/744 02:17 < 01:34, 3.20 it/s, Epoch 7/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Mcc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.245400</td>\n","      <td>0.139774</td>\n","      <td>0.719780</td>\n","      <td>0.786316</td>\n","      <td>0.719780</td>\n","      <td>0.733039</td>\n","      <td>0.563940</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.067900</td>\n","      <td>0.046219</td>\n","      <td>0.845654</td>\n","      <td>0.869895</td>\n","      <td>0.845654</td>\n","      <td>0.853214</td>\n","      <td>0.750679</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.034600</td>\n","      <td>0.049218</td>\n","      <td>0.859141</td>\n","      <td>0.880639</td>\n","      <td>0.859141</td>\n","      <td>0.865398</td>\n","      <td>0.768748</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.021200</td>\n","      <td>0.033884</td>\n","      <td>0.907093</td>\n","      <td>0.912594</td>\n","      <td>0.907093</td>\n","      <td>0.908414</td>\n","      <td>0.839031</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.014200</td>\n","      <td>0.043796</td>\n","      <td>0.882118</td>\n","      <td>0.901121</td>\n","      <td>0.882118</td>\n","      <td>0.887154</td>\n","      <td>0.808283</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.009300</td>\n","      <td>0.042776</td>\n","      <td>0.885115</td>\n","      <td>0.901253</td>\n","      <td>0.885115</td>\n","      <td>0.889491</td>\n","      <td>0.812908</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.007000</td>\n","      <td>0.039210</td>\n","      <td>0.898601</td>\n","      <td>0.905884</td>\n","      <td>0.898601</td>\n","      <td>0.900621</td>\n","      <td>0.828308</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ Best model saved to /content/drive/MyDrive/RoBERTa_8_Results/glowing-sweep-5/best_model\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▆▆█▇▇██</td></tr><tr><td>eval/f1</td><td>▁▆▆█▇▇██</td></tr><tr><td>eval/loss</td><td>█▂▂▁▂▂▁▁</td></tr><tr><td>eval/mcc</td><td>▁▆▆█▇▇██</td></tr><tr><td>eval/precision</td><td>▁▆▆█▇▇██</td></tr><tr><td>eval/recall</td><td>▁▆▆█▇▇██</td></tr><tr><td>eval/runtime</td><td>▅▄▁█▁▅▆▇</td></tr><tr><td>eval/samples_per_second</td><td>▄▅█▁█▄▂▂</td></tr><tr><td>eval/steps_per_second</td><td>▄▅█▁█▄▂▂</td></tr><tr><td>eval_accuracy</td><td>▁</td></tr><tr><td>eval_f1</td><td>▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_mcc</td><td>▁</td></tr><tr><td>eval_precision</td><td>▁</td></tr><tr><td>eval_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/mcc</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▅▅▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▅▅▆▆▇▇██████</td></tr><tr><td>train/grad_norm</td><td>▄▄█▃▂▁▁</td></tr><tr><td>train/learning_rate</td><td>▆█▇▆▅▃▁</td></tr><tr><td>train/loss</td><td>█▃▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.90709</td></tr><tr><td>eval/f1</td><td>0.90841</td></tr><tr><td>eval/loss</td><td>0.03388</td></tr><tr><td>eval/mcc</td><td>0.83903</td></tr><tr><td>eval/precision</td><td>0.91259</td></tr><tr><td>eval/recall</td><td>0.90709</td></tr><tr><td>eval/runtime</td><td>0.9302</td></tr><tr><td>eval/samples_per_second</td><td>2152.117</td></tr><tr><td>eval/steps_per_second</td><td>67.724</td></tr><tr><td>eval_accuracy</td><td>0.90709</td></tr><tr><td>eval_f1</td><td>0.90841</td></tr><tr><td>eval_loss</td><td>0.03388</td></tr><tr><td>eval_mcc</td><td>0.83903</td></tr><tr><td>eval_precision</td><td>0.91259</td></tr><tr><td>eval_recall</td><td>0.90709</td></tr><tr><td>test/accuracy</td><td>0.90709</td></tr><tr><td>test/f1</td><td>0.90841</td></tr><tr><td>test/loss</td><td>0.03388</td></tr><tr><td>test/mcc</td><td>0.83903</td></tr><tr><td>test/precision</td><td>0.91259</td></tr><tr><td>test/recall</td><td>0.90709</td></tr><tr><td>test/runtime</td><td>1.0482</td></tr><tr><td>test/samples_per_second</td><td>1909.963</td></tr><tr><td>test/steps_per_second</td><td>60.104</td></tr><tr><td>total_flos</td><td>3340070550819072.0</td></tr><tr><td>train/epoch</td><td>7</td></tr><tr><td>train/global_step</td><td>441</td></tr><tr><td>train/grad_norm</td><td>0.28619</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>0.007</td></tr><tr><td>train_loss</td><td>0.05708</td></tr><tr><td>train_runtime</td><td>137.5488</td></tr><tr><td>train_samples_per_second</td><td>698.283</td></tr><tr><td>train_steps_per_second</td><td>5.409</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">glowing-sweep-5</strong> at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/kad96j3k' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/kad96j3k</a><br> View project at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250218_020557-kad96j3k/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: p8goepgm with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.13159836812757766\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2.992669825033802e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_grad_norm: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 12\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.04751580312720266\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.6"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250218_020829-p8goepgm</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/p8goepgm' target=\"_blank\">decent-sweep-6</a></strong> to <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/p8goepgm' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/p8goepgm</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Total Steps: 756, Warmup Steps (10%): 75\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_grad_norm' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_train_epochs' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='441' max='744' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [441/744 02:15 < 01:33, 3.25 it/s, Epoch 7/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Mcc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.278100</td>\n","      <td>0.190817</td>\n","      <td>0.644356</td>\n","      <td>0.640784</td>\n","      <td>0.644356</td>\n","      <td>0.625954</td>\n","      <td>0.420166</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.092100</td>\n","      <td>0.048006</td>\n","      <td>0.861139</td>\n","      <td>0.872119</td>\n","      <td>0.861139</td>\n","      <td>0.863889</td>\n","      <td>0.761301</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.036000</td>\n","      <td>0.034610</td>\n","      <td>0.893606</td>\n","      <td>0.895789</td>\n","      <td>0.893606</td>\n","      <td>0.894183</td>\n","      <td>0.813278</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.021900</td>\n","      <td>0.034339</td>\n","      <td>0.902098</td>\n","      <td>0.904846</td>\n","      <td>0.902098</td>\n","      <td>0.901423</td>\n","      <td>0.826107</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.013100</td>\n","      <td>0.056012</td>\n","      <td>0.861638</td>\n","      <td>0.888439</td>\n","      <td>0.861638</td>\n","      <td>0.869130</td>\n","      <td>0.776332</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.010300</td>\n","      <td>0.035778</td>\n","      <td>0.896603</td>\n","      <td>0.907457</td>\n","      <td>0.896603</td>\n","      <td>0.899893</td>\n","      <td>0.826769</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.006200</td>\n","      <td>0.034855</td>\n","      <td>0.905594</td>\n","      <td>0.911563</td>\n","      <td>0.905594</td>\n","      <td>0.907424</td>\n","      <td>0.837940</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ Best model saved to /content/drive/MyDrive/RoBERTa_8_Results/decent-sweep-6/best_model\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▇██▇███</td></tr><tr><td>eval/f1</td><td>▁▇██▇███</td></tr><tr><td>eval/loss</td><td>█▂▁▁▂▁▁▁</td></tr><tr><td>eval/mcc</td><td>▁▇██▇███</td></tr><tr><td>eval/precision</td><td>▁▇██▇███</td></tr><tr><td>eval/recall</td><td>▁▇██▇███</td></tr><tr><td>eval/runtime</td><td>▁▂▄█▂▆▁▅</td></tr><tr><td>eval/samples_per_second</td><td>█▇▅▁▇▃█▄</td></tr><tr><td>eval/steps_per_second</td><td>█▇▅▁▇▃█▄</td></tr><tr><td>eval_accuracy</td><td>▁</td></tr><tr><td>eval_f1</td><td>▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_mcc</td><td>▁</td></tr><tr><td>eval_precision</td><td>▁</td></tr><tr><td>eval_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/mcc</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▅▅▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▅▅▆▆▇▇██████</td></tr><tr><td>train/grad_norm</td><td>▅▂█▁▃▂▁</td></tr><tr><td>train/learning_rate</td><td>▆█▇▆▅▃▁</td></tr><tr><td>train/loss</td><td>█▃▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.9021</td></tr><tr><td>eval/f1</td><td>0.90142</td></tr><tr><td>eval/loss</td><td>0.03434</td></tr><tr><td>eval/mcc</td><td>0.82611</td></tr><tr><td>eval/precision</td><td>0.90485</td></tr><tr><td>eval/recall</td><td>0.9021</td></tr><tr><td>eval/runtime</td><td>0.9226</td></tr><tr><td>eval/samples_per_second</td><td>2170.011</td></tr><tr><td>eval/steps_per_second</td><td>68.287</td></tr><tr><td>eval_accuracy</td><td>0.9021</td></tr><tr><td>eval_f1</td><td>0.90142</td></tr><tr><td>eval_loss</td><td>0.03434</td></tr><tr><td>eval_mcc</td><td>0.82611</td></tr><tr><td>eval_precision</td><td>0.90485</td></tr><tr><td>eval_recall</td><td>0.9021</td></tr><tr><td>test/accuracy</td><td>0.9021</td></tr><tr><td>test/f1</td><td>0.90142</td></tr><tr><td>test/loss</td><td>0.03434</td></tr><tr><td>test/mcc</td><td>0.82611</td></tr><tr><td>test/precision</td><td>0.90485</td></tr><tr><td>test/recall</td><td>0.9021</td></tr><tr><td>test/runtime</td><td>1.0018</td></tr><tr><td>test/samples_per_second</td><td>1998.489</td></tr><tr><td>test/steps_per_second</td><td>62.89</td></tr><tr><td>total_flos</td><td>3340070550819072.0</td></tr><tr><td>train/epoch</td><td>7</td></tr><tr><td>train/global_step</td><td>441</td></tr><tr><td>train/grad_norm</td><td>0.52386</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.0062</td></tr><tr><td>train_loss</td><td>0.06539</td></tr><tr><td>train_runtime</td><td>135.5351</td></tr><tr><td>train_samples_per_second</td><td>708.658</td></tr><tr><td>train_steps_per_second</td><td>5.489</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">decent-sweep-6</strong> at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/p8goepgm' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/p8goepgm</a><br> View project at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250218_020829-p8goepgm/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4izdxmdj with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.07801351074950956\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3.4067257383710574e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_grad_norm: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 12\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.037063915608556784\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.6"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250218_021057-4izdxmdj</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/4izdxmdj' target=\"_blank\">fancy-sweep-7</a></strong> to <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/4izdxmdj' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/4izdxmdj</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Total Steps: 756, Warmup Steps (10%): 75\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_grad_norm' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_train_epochs' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='567' max='744' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [567/744 02:53 < 00:54, 3.25 it/s, Epoch 9/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Mcc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.265600</td>\n","      <td>0.142829</td>\n","      <td>0.740759</td>\n","      <td>0.798074</td>\n","      <td>0.740759</td>\n","      <td>0.734170</td>\n","      <td>0.556368</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.071400</td>\n","      <td>0.042706</td>\n","      <td>0.868132</td>\n","      <td>0.882175</td>\n","      <td>0.868132</td>\n","      <td>0.872510</td>\n","      <td>0.778233</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.027400</td>\n","      <td>0.043430</td>\n","      <td>0.874126</td>\n","      <td>0.888273</td>\n","      <td>0.874126</td>\n","      <td>0.877689</td>\n","      <td>0.788704</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.015400</td>\n","      <td>0.036203</td>\n","      <td>0.908092</td>\n","      <td>0.911202</td>\n","      <td>0.908092</td>\n","      <td>0.906924</td>\n","      <td>0.834757</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.007700</td>\n","      <td>0.033510</td>\n","      <td>0.914086</td>\n","      <td>0.918381</td>\n","      <td>0.914086</td>\n","      <td>0.915072</td>\n","      <td>0.849831</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.004500</td>\n","      <td>0.031383</td>\n","      <td>0.919580</td>\n","      <td>0.921643</td>\n","      <td>0.919580</td>\n","      <td>0.920131</td>\n","      <td>0.858259</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.002500</td>\n","      <td>0.033789</td>\n","      <td>0.912587</td>\n","      <td>0.919221</td>\n","      <td>0.912587</td>\n","      <td>0.914738</td>\n","      <td>0.848068</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.001600</td>\n","      <td>0.032886</td>\n","      <td>0.918581</td>\n","      <td>0.920765</td>\n","      <td>0.918581</td>\n","      <td>0.919361</td>\n","      <td>0.857009</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.001200</td>\n","      <td>0.032829</td>\n","      <td>0.923576</td>\n","      <td>0.925023</td>\n","      <td>0.923576</td>\n","      <td>0.924142</td>\n","      <td>0.865553</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ Best model saved to /content/drive/MyDrive/RoBERTa_8_Results/fancy-sweep-7/best_model\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▆▆▇██████</td></tr><tr><td>eval/f1</td><td>▁▆▆▇██████</td></tr><tr><td>eval/loss</td><td>█▂▂▁▁▁▁▁▁▁</td></tr><tr><td>eval/mcc</td><td>▁▆▆▇██████</td></tr><tr><td>eval/precision</td><td>▁▆▆▇██████</td></tr><tr><td>eval/recall</td><td>▁▆▆▇██████</td></tr><tr><td>eval/runtime</td><td>▁▃▁▃▁▄▂█▁▇</td></tr><tr><td>eval/samples_per_second</td><td>█▆█▆█▅▇▁█▂</td></tr><tr><td>eval/steps_per_second</td><td>█▆█▆█▅▇▁█▂</td></tr><tr><td>eval_accuracy</td><td>▁</td></tr><tr><td>eval_f1</td><td>▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_mcc</td><td>▁</td></tr><tr><td>eval_precision</td><td>▁</td></tr><tr><td>eval_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/mcc</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▄▄▅▅▅▅▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▄▄▅▅▅▅▆▆▇▇██████</td></tr><tr><td>train/grad_norm</td><td>▅▃█▃▁▂▄▁▁</td></tr><tr><td>train/learning_rate</td><td>▇██▇▆▄▃▂▁</td></tr><tr><td>train/loss</td><td>█▃▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.91958</td></tr><tr><td>eval/f1</td><td>0.92013</td></tr><tr><td>eval/loss</td><td>0.03138</td></tr><tr><td>eval/mcc</td><td>0.85826</td></tr><tr><td>eval/precision</td><td>0.92164</td></tr><tr><td>eval/recall</td><td>0.91958</td></tr><tr><td>eval/runtime</td><td>0.9484</td></tr><tr><td>eval/samples_per_second</td><td>2110.937</td></tr><tr><td>eval/steps_per_second</td><td>66.428</td></tr><tr><td>eval_accuracy</td><td>0.91958</td></tr><tr><td>eval_f1</td><td>0.92013</td></tr><tr><td>eval_loss</td><td>0.03138</td></tr><tr><td>eval_mcc</td><td>0.85826</td></tr><tr><td>eval_precision</td><td>0.92164</td></tr><tr><td>eval_recall</td><td>0.91958</td></tr><tr><td>test/accuracy</td><td>0.91958</td></tr><tr><td>test/f1</td><td>0.92013</td></tr><tr><td>test/loss</td><td>0.03138</td></tr><tr><td>test/mcc</td><td>0.85826</td></tr><tr><td>test/precision</td><td>0.92164</td></tr><tr><td>test/recall</td><td>0.91958</td></tr><tr><td>test/runtime</td><td>1.0153</td></tr><tr><td>test/samples_per_second</td><td>1971.756</td></tr><tr><td>test/steps_per_second</td><td>62.048</td></tr><tr><td>total_flos</td><td>4294376422481664.0</td></tr><tr><td>train/epoch</td><td>9</td></tr><tr><td>train/global_step</td><td>567</td></tr><tr><td>train/grad_norm</td><td>0.16321</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.0012</td></tr><tr><td>train_loss</td><td>0.04414</td></tr><tr><td>train_runtime</td><td>174.2645</td></tr><tr><td>train_samples_per_second</td><td>551.162</td></tr><tr><td>train_steps_per_second</td><td>4.269</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">fancy-sweep-7</strong> at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/4izdxmdj' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/4izdxmdj</a><br> View project at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250218_021057-4izdxmdj/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ozk0n8i3 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.14018576004372665\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 4.5250407918001944e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_grad_norm: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 12\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.04882860599112413\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.6"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250218_021406-ozk0n8i3</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/ozk0n8i3' target=\"_blank\">magic-sweep-8</a></strong> to <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/ozk0n8i3' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/ozk0n8i3</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Total Steps: 1512, Warmup Steps (10%): 151\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_grad_norm' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_train_epochs' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='882' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 882/1500 02:20 < 01:38, 6.28 it/s, Epoch 7/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Mcc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.195900</td>\n","      <td>0.058872</td>\n","      <td>0.853147</td>\n","      <td>0.862243</td>\n","      <td>0.853147</td>\n","      <td>0.847164</td>\n","      <td>0.733501</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.046000</td>\n","      <td>0.050364</td>\n","      <td>0.852148</td>\n","      <td>0.885001</td>\n","      <td>0.852148</td>\n","      <td>0.861201</td>\n","      <td>0.766179</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.025900</td>\n","      <td>0.044663</td>\n","      <td>0.877622</td>\n","      <td>0.894005</td>\n","      <td>0.877622</td>\n","      <td>0.881612</td>\n","      <td>0.797937</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.015300</td>\n","      <td>0.034008</td>\n","      <td>0.916583</td>\n","      <td>0.916451</td>\n","      <td>0.916583</td>\n","      <td>0.915398</td>\n","      <td>0.850841</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.009400</td>\n","      <td>0.041547</td>\n","      <td>0.905095</td>\n","      <td>0.912489</td>\n","      <td>0.905095</td>\n","      <td>0.907346</td>\n","      <td>0.838358</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.005500</td>\n","      <td>0.036754</td>\n","      <td>0.914086</td>\n","      <td>0.916748</td>\n","      <td>0.914086</td>\n","      <td>0.915109</td>\n","      <td>0.850110</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.003900</td>\n","      <td>0.040848</td>\n","      <td>0.903596</td>\n","      <td>0.909867</td>\n","      <td>0.903596</td>\n","      <td>0.905355</td>\n","      <td>0.835158</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ Best model saved to /content/drive/MyDrive/RoBERTa_8_Results/magic-sweep-8/best_model\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▁▄█▇█▇█</td></tr><tr><td>eval/f1</td><td>▁▂▅█▇█▇█</td></tr><tr><td>eval/loss</td><td>█▆▄▁▃▂▃▁</td></tr><tr><td>eval/mcc</td><td>▁▃▅█▇█▇█</td></tr><tr><td>eval/precision</td><td>▁▄▅█▇█▇█</td></tr><tr><td>eval/recall</td><td>▁▁▄█▇█▇█</td></tr><tr><td>eval/runtime</td><td>▁▃▁▇▄▂█▃</td></tr><tr><td>eval/samples_per_second</td><td>█▆█▂▅▇▁▆</td></tr><tr><td>eval/steps_per_second</td><td>█▆█▂▅▇▁▆</td></tr><tr><td>eval_accuracy</td><td>▁</td></tr><tr><td>eval_f1</td><td>▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_mcc</td><td>▁</td></tr><tr><td>eval_precision</td><td>▁</td></tr><tr><td>eval_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/mcc</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▅▅▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▅▅▆▆▇▇██████</td></tr><tr><td>train/grad_norm</td><td>▅▃▃█▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▆█▇▆▅▃▁</td></tr><tr><td>train/loss</td><td>█▃▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.91658</td></tr><tr><td>eval/f1</td><td>0.9154</td></tr><tr><td>eval/loss</td><td>0.03401</td></tr><tr><td>eval/mcc</td><td>0.85084</td></tr><tr><td>eval/precision</td><td>0.91645</td></tr><tr><td>eval/recall</td><td>0.91658</td></tr><tr><td>eval/runtime</td><td>0.9139</td></tr><tr><td>eval/samples_per_second</td><td>2190.562</td></tr><tr><td>eval/steps_per_second</td><td>68.934</td></tr><tr><td>eval_accuracy</td><td>0.91658</td></tr><tr><td>eval_f1</td><td>0.9154</td></tr><tr><td>eval_loss</td><td>0.03401</td></tr><tr><td>eval_mcc</td><td>0.85084</td></tr><tr><td>eval_precision</td><td>0.91645</td></tr><tr><td>eval_recall</td><td>0.91658</td></tr><tr><td>test/accuracy</td><td>0.91658</td></tr><tr><td>test/f1</td><td>0.9154</td></tr><tr><td>test/loss</td><td>0.03401</td></tr><tr><td>test/mcc</td><td>0.85084</td></tr><tr><td>test/precision</td><td>0.91645</td></tr><tr><td>test/recall</td><td>0.91658</td></tr><tr><td>test/runtime</td><td>1.0224</td></tr><tr><td>test/samples_per_second</td><td>1958.222</td></tr><tr><td>test/steps_per_second</td><td>61.622</td></tr><tr><td>total_flos</td><td>3340070550819072.0</td></tr><tr><td>train/epoch</td><td>7</td></tr><tr><td>train/global_step</td><td>882</td></tr><tr><td>train/grad_norm</td><td>0.06948</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>0.0039</td></tr><tr><td>train_loss</td><td>0.04313</td></tr><tr><td>train_runtime</td><td>140.3391</td></tr><tr><td>train_samples_per_second</td><td>684.4</td></tr><tr><td>train_steps_per_second</td><td>10.688</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">magic-sweep-8</strong> at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/ozk0n8i3' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/ozk0n8i3</a><br> View project at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250218_021406-ozk0n8i3/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 78j24vdx with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.053896416231812766\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3.423775487589857e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_grad_norm: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 12\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.048628282054960344\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.6"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250218_021640-78j24vdx</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/78j24vdx' target=\"_blank\">faithful-sweep-9</a></strong> to <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/78j24vdx' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/78j24vdx</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Total Steps: 1512, Warmup Steps (10%): 151\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_grad_norm' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_train_epochs' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='882' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 882/1500 02:20 < 01:38, 6.26 it/s, Epoch 7/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Mcc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.203500</td>\n","      <td>0.059312</td>\n","      <td>0.850649</td>\n","      <td>0.865122</td>\n","      <td>0.850649</td>\n","      <td>0.853513</td>\n","      <td>0.745546</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.040100</td>\n","      <td>0.035315</td>\n","      <td>0.894106</td>\n","      <td>0.897921</td>\n","      <td>0.894106</td>\n","      <td>0.895167</td>\n","      <td>0.816532</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.020100</td>\n","      <td>0.039594</td>\n","      <td>0.900100</td>\n","      <td>0.908221</td>\n","      <td>0.900100</td>\n","      <td>0.901685</td>\n","      <td>0.827285</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.009800</td>\n","      <td>0.034273</td>\n","      <td>0.924575</td>\n","      <td>0.926748</td>\n","      <td>0.924575</td>\n","      <td>0.922729</td>\n","      <td>0.864173</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.003400</td>\n","      <td>0.037141</td>\n","      <td>0.912587</td>\n","      <td>0.921123</td>\n","      <td>0.912587</td>\n","      <td>0.915012</td>\n","      <td>0.850156</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.001900</td>\n","      <td>0.044717</td>\n","      <td>0.913586</td>\n","      <td>0.915424</td>\n","      <td>0.913586</td>\n","      <td>0.910518</td>\n","      <td>0.844458</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.001200</td>\n","      <td>0.038224</td>\n","      <td>0.927073</td>\n","      <td>0.927066</td>\n","      <td>0.927073</td>\n","      <td>0.926191</td>\n","      <td>0.869360</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ Best model saved to /content/drive/MyDrive/RoBERTa_8_Results/faithful-sweep-9/best_model\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▅▆█▇▇██</td></tr><tr><td>eval/f1</td><td>▁▅▆█▇▆██</td></tr><tr><td>eval/loss</td><td>█▁▂▁▂▄▂▁</td></tr><tr><td>eval/mcc</td><td>▁▅▆█▇▇██</td></tr><tr><td>eval/precision</td><td>▁▅▆█▇▇██</td></tr><tr><td>eval/recall</td><td>▁▅▆█▇▇██</td></tr><tr><td>eval/runtime</td><td>▅▄▃▆█▁▁▄</td></tr><tr><td>eval/samples_per_second</td><td>▄▅▆▃▁██▅</td></tr><tr><td>eval/steps_per_second</td><td>▄▅▆▃▁██▅</td></tr><tr><td>eval_accuracy</td><td>▁</td></tr><tr><td>eval_f1</td><td>▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_mcc</td><td>▁</td></tr><tr><td>eval_precision</td><td>▁</td></tr><tr><td>eval_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/mcc</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▅▅▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▅▅▆▆▇▇██████</td></tr><tr><td>train/grad_norm</td><td>█▂▆▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▆█▇▆▅▃▁</td></tr><tr><td>train/loss</td><td>█▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.92458</td></tr><tr><td>eval/f1</td><td>0.92273</td></tr><tr><td>eval/loss</td><td>0.03427</td></tr><tr><td>eval/mcc</td><td>0.86417</td></tr><tr><td>eval/precision</td><td>0.92675</td></tr><tr><td>eval/recall</td><td>0.92458</td></tr><tr><td>eval/runtime</td><td>0.9233</td></tr><tr><td>eval/samples_per_second</td><td>2168.374</td></tr><tr><td>eval/steps_per_second</td><td>68.236</td></tr><tr><td>eval_accuracy</td><td>0.92458</td></tr><tr><td>eval_f1</td><td>0.92273</td></tr><tr><td>eval_loss</td><td>0.03427</td></tr><tr><td>eval_mcc</td><td>0.86417</td></tr><tr><td>eval_precision</td><td>0.92675</td></tr><tr><td>eval_recall</td><td>0.92458</td></tr><tr><td>test/accuracy</td><td>0.92458</td></tr><tr><td>test/f1</td><td>0.92273</td></tr><tr><td>test/loss</td><td>0.03427</td></tr><tr><td>test/mcc</td><td>0.86417</td></tr><tr><td>test/precision</td><td>0.92675</td></tr><tr><td>test/recall</td><td>0.92458</td></tr><tr><td>test/runtime</td><td>1.0326</td></tr><tr><td>test/samples_per_second</td><td>1938.887</td></tr><tr><td>test/steps_per_second</td><td>61.014</td></tr><tr><td>total_flos</td><td>3340070550819072.0</td></tr><tr><td>train/epoch</td><td>7</td></tr><tr><td>train/global_step</td><td>882</td></tr><tr><td>train/grad_norm</td><td>0.00114</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.0012</td></tr><tr><td>train_loss</td><td>0.03999</td></tr><tr><td>train_runtime</td><td>140.7175</td></tr><tr><td>train_samples_per_second</td><td>682.559</td></tr><tr><td>train_steps_per_second</td><td>10.66</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">faithful-sweep-9</strong> at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/78j24vdx' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/78j24vdx</a><br> View project at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250218_021640-78j24vdx/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fw438e87 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.10017176068297476\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3.606612923512613e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_grad_norm: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 12\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0407276415611722\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.6"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250218_021913-fw438e87</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/fw438e87' target=\"_blank\">treasured-sweep-10</a></strong> to <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/fw438e87' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/fw438e87</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Total Steps: 756, Warmup Steps (10%): 75\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_grad_norm' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_train_epochs' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='567' max='744' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [567/744 02:53 < 00:54, 3.25 it/s, Epoch 9/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Mcc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.264800</td>\n","      <td>0.145752</td>\n","      <td>0.724775</td>\n","      <td>0.777635</td>\n","      <td>0.724775</td>\n","      <td>0.735426</td>\n","      <td>0.546233</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.070600</td>\n","      <td>0.043484</td>\n","      <td>0.864136</td>\n","      <td>0.882477</td>\n","      <td>0.864136</td>\n","      <td>0.868745</td>\n","      <td>0.770091</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.030300</td>\n","      <td>0.032824</td>\n","      <td>0.896603</td>\n","      <td>0.902484</td>\n","      <td>0.896603</td>\n","      <td>0.898047</td>\n","      <td>0.820676</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.015900</td>\n","      <td>0.033127</td>\n","      <td>0.914086</td>\n","      <td>0.918328</td>\n","      <td>0.914086</td>\n","      <td>0.913209</td>\n","      <td>0.847068</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.009400</td>\n","      <td>0.032631</td>\n","      <td>0.906593</td>\n","      <td>0.913482</td>\n","      <td>0.906593</td>\n","      <td>0.908133</td>\n","      <td>0.838208</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.005600</td>\n","      <td>0.029538</td>\n","      <td>0.917582</td>\n","      <td>0.921297</td>\n","      <td>0.917582</td>\n","      <td>0.918503</td>\n","      <td>0.856601</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.003400</td>\n","      <td>0.031846</td>\n","      <td>0.915584</td>\n","      <td>0.921434</td>\n","      <td>0.915584</td>\n","      <td>0.917457</td>\n","      <td>0.854763</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.002000</td>\n","      <td>0.032370</td>\n","      <td>0.923576</td>\n","      <td>0.927417</td>\n","      <td>0.923576</td>\n","      <td>0.924810</td>\n","      <td>0.866697</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.001600</td>\n","      <td>0.033691</td>\n","      <td>0.920579</td>\n","      <td>0.924902</td>\n","      <td>0.920579</td>\n","      <td>0.922001</td>\n","      <td>0.862727</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ Best model saved to /content/drive/MyDrive/RoBERTa_8_Results/treasured-sweep-10/best_model\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▆▇█▇█████</td></tr><tr><td>eval/f1</td><td>▁▆▇█▇█████</td></tr><tr><td>eval/loss</td><td>█▂▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/mcc</td><td>▁▆▇█▇█████</td></tr><tr><td>eval/precision</td><td>▁▆▇█▇█████</td></tr><tr><td>eval/recall</td><td>▁▆▇█▇█████</td></tr><tr><td>eval/runtime</td><td>▂▂▄▁█▁▁▁▂▄</td></tr><tr><td>eval/samples_per_second</td><td>▇▇▅█▁███▇▅</td></tr><tr><td>eval/steps_per_second</td><td>▇▇▅█▁███▇▅</td></tr><tr><td>eval_accuracy</td><td>▁</td></tr><tr><td>eval_f1</td><td>▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_mcc</td><td>▁</td></tr><tr><td>eval_precision</td><td>▁</td></tr><tr><td>eval_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/mcc</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▄▄▅▅▅▅▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▄▄▅▅▅▅▆▆▇▇██████</td></tr><tr><td>train/grad_norm</td><td>▃▂█▂▂▂▃▁▁</td></tr><tr><td>train/learning_rate</td><td>▇██▇▆▄▃▂▁</td></tr><tr><td>train/loss</td><td>█▃▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.91758</td></tr><tr><td>eval/f1</td><td>0.9185</td></tr><tr><td>eval/loss</td><td>0.02954</td></tr><tr><td>eval/mcc</td><td>0.8566</td></tr><tr><td>eval/precision</td><td>0.9213</td></tr><tr><td>eval/recall</td><td>0.91758</td></tr><tr><td>eval/runtime</td><td>0.9232</td></tr><tr><td>eval/samples_per_second</td><td>2168.565</td></tr><tr><td>eval/steps_per_second</td><td>68.242</td></tr><tr><td>eval_accuracy</td><td>0.91758</td></tr><tr><td>eval_f1</td><td>0.9185</td></tr><tr><td>eval_loss</td><td>0.02954</td></tr><tr><td>eval_mcc</td><td>0.8566</td></tr><tr><td>eval_precision</td><td>0.9213</td></tr><tr><td>eval_recall</td><td>0.91758</td></tr><tr><td>test/accuracy</td><td>0.91758</td></tr><tr><td>test/f1</td><td>0.9185</td></tr><tr><td>test/loss</td><td>0.02954</td></tr><tr><td>test/mcc</td><td>0.8566</td></tr><tr><td>test/precision</td><td>0.9213</td></tr><tr><td>test/recall</td><td>0.91758</td></tr><tr><td>test/runtime</td><td>1.0185</td></tr><tr><td>test/samples_per_second</td><td>1965.654</td></tr><tr><td>test/steps_per_second</td><td>61.856</td></tr><tr><td>total_flos</td><td>4294376422481664.0</td></tr><tr><td>train/epoch</td><td>9</td></tr><tr><td>train/global_step</td><td>567</td></tr><tr><td>train/grad_norm</td><td>0.11552</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.0016</td></tr><tr><td>train_loss</td><td>0.04485</td></tr><tr><td>train_runtime</td><td>173.9985</td></tr><tr><td>train_samples_per_second</td><td>552.005</td></tr><tr><td>train_steps_per_second</td><td>4.276</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">treasured-sweep-10</strong> at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/fw438e87' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/fw438e87</a><br> View project at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250218_021913-fw438e87/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: d1t95e36 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.058529503694848654\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 4.300495514427046e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_grad_norm: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 12\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.04230420352896582\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.6"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250218_022222-d1t95e36</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/d1t95e36' target=\"_blank\">comic-sweep-11</a></strong> to <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/d1t95e36' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/d1t95e36</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Total Steps: 756, Warmup Steps (10%): 75\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_grad_norm' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_train_epochs' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='504' max='744' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [504/744 02:34 < 01:13, 3.25 it/s, Epoch 8/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Mcc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.239900</td>\n","      <td>0.104190</td>\n","      <td>0.777722</td>\n","      <td>0.816962</td>\n","      <td>0.777722</td>\n","      <td>0.779972</td>\n","      <td>0.633577</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.048100</td>\n","      <td>0.039400</td>\n","      <td>0.879620</td>\n","      <td>0.901855</td>\n","      <td>0.879620</td>\n","      <td>0.885491</td>\n","      <td>0.803647</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.020000</td>\n","      <td>0.035184</td>\n","      <td>0.896603</td>\n","      <td>0.911265</td>\n","      <td>0.896603</td>\n","      <td>0.900702</td>\n","      <td>0.822680</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.010100</td>\n","      <td>0.034209</td>\n","      <td>0.914086</td>\n","      <td>0.917625</td>\n","      <td>0.914086</td>\n","      <td>0.913728</td>\n","      <td>0.848337</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.005000</td>\n","      <td>0.031090</td>\n","      <td>0.929071</td>\n","      <td>0.930645</td>\n","      <td>0.929071</td>\n","      <td>0.929465</td>\n","      <td>0.874437</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.002000</td>\n","      <td>0.033170</td>\n","      <td>0.921079</td>\n","      <td>0.921507</td>\n","      <td>0.921079</td>\n","      <td>0.919733</td>\n","      <td>0.859064</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.001200</td>\n","      <td>0.033157</td>\n","      <td>0.926074</td>\n","      <td>0.926308</td>\n","      <td>0.926074</td>\n","      <td>0.925569</td>\n","      <td>0.868254</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.000700</td>\n","      <td>0.032365</td>\n","      <td>0.926573</td>\n","      <td>0.928196</td>\n","      <td>0.926573</td>\n","      <td>0.927129</td>\n","      <td>0.870622</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ Best model saved to /content/drive/MyDrive/RoBERTa_8_Results/comic-sweep-11/best_model\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▆▆▇█████</td></tr><tr><td>eval/f1</td><td>▁▆▇▇█████</td></tr><tr><td>eval/loss</td><td>█▂▁▁▁▁▁▁▁</td></tr><tr><td>eval/mcc</td><td>▁▆▆▇█████</td></tr><tr><td>eval/precision</td><td>▁▆▇▇█▇███</td></tr><tr><td>eval/recall</td><td>▁▆▆▇█████</td></tr><tr><td>eval/runtime</td><td>▁▂▅▂▄▄▂▁█</td></tr><tr><td>eval/samples_per_second</td><td>█▆▄▇▅▅▇█▁</td></tr><tr><td>eval/steps_per_second</td><td>█▆▄▇▅▅▇█▁</td></tr><tr><td>eval_accuracy</td><td>▁</td></tr><tr><td>eval_f1</td><td>▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_mcc</td><td>▁</td></tr><tr><td>eval_precision</td><td>▁</td></tr><tr><td>eval_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/mcc</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▇▇██████</td></tr><tr><td>train/grad_norm</td><td>█▃▃█▂▂▁▁</td></tr><tr><td>train/learning_rate</td><td>▇█▇▇▅▄▂▁</td></tr><tr><td>train/loss</td><td>█▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.92907</td></tr><tr><td>eval/f1</td><td>0.92947</td></tr><tr><td>eval/loss</td><td>0.03109</td></tr><tr><td>eval/mcc</td><td>0.87444</td></tr><tr><td>eval/precision</td><td>0.93065</td></tr><tr><td>eval/recall</td><td>0.92907</td></tr><tr><td>eval/runtime</td><td>0.9992</td></tr><tr><td>eval/samples_per_second</td><td>2003.519</td></tr><tr><td>eval/steps_per_second</td><td>63.048</td></tr><tr><td>eval_accuracy</td><td>0.92907</td></tr><tr><td>eval_f1</td><td>0.92947</td></tr><tr><td>eval_loss</td><td>0.03109</td></tr><tr><td>eval_mcc</td><td>0.87444</td></tr><tr><td>eval_precision</td><td>0.93065</td></tr><tr><td>eval_recall</td><td>0.92907</td></tr><tr><td>test/accuracy</td><td>0.92907</td></tr><tr><td>test/f1</td><td>0.92947</td></tr><tr><td>test/loss</td><td>0.03109</td></tr><tr><td>test/mcc</td><td>0.87444</td></tr><tr><td>test/precision</td><td>0.93065</td></tr><tr><td>test/recall</td><td>0.92907</td></tr><tr><td>test/runtime</td><td>1.055</td></tr><tr><td>test/samples_per_second</td><td>1897.704</td></tr><tr><td>test/steps_per_second</td><td>59.718</td></tr><tr><td>total_flos</td><td>3817223486650368.0</td></tr><tr><td>train/epoch</td><td>8</td></tr><tr><td>train/global_step</td><td>504</td></tr><tr><td>train/grad_norm</td><td>0.18938</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.0007</td></tr><tr><td>train_loss</td><td>0.04088</td></tr><tr><td>train_runtime</td><td>154.9188</td></tr><tr><td>train_samples_per_second</td><td>619.989</td></tr><tr><td>train_steps_per_second</td><td>4.803</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">comic-sweep-11</strong> at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/d1t95e36' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/d1t95e36</a><br> View project at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250218_022222-d1t95e36/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4q85n5bj with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.06980858494928484\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.53925407401223e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_grad_norm: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 12\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.047315646905475954\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.6"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250218_022513-4q85n5bj</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/4q85n5bj' target=\"_blank\">glad-sweep-12</a></strong> to <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/4q85n5bj' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/4q85n5bj</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Total Steps: 1512, Warmup Steps (10%): 151\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_grad_norm' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_train_epochs' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='882' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 882/1500 02:20 < 01:38, 6.27 it/s, Epoch 7/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Mcc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.250900</td>\n","      <td>0.115364</td>\n","      <td>0.756743</td>\n","      <td>0.764152</td>\n","      <td>0.756743</td>\n","      <td>0.746059</td>\n","      <td>0.571296</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.061800</td>\n","      <td>0.039941</td>\n","      <td>0.881618</td>\n","      <td>0.890605</td>\n","      <td>0.881618</td>\n","      <td>0.883044</td>\n","      <td>0.795095</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.025100</td>\n","      <td>0.045677</td>\n","      <td>0.878621</td>\n","      <td>0.892599</td>\n","      <td>0.878621</td>\n","      <td>0.882214</td>\n","      <td>0.795294</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.013800</td>\n","      <td>0.032779</td>\n","      <td>0.918581</td>\n","      <td>0.917901</td>\n","      <td>0.918581</td>\n","      <td>0.916557</td>\n","      <td>0.852635</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.007900</td>\n","      <td>0.037782</td>\n","      <td>0.909590</td>\n","      <td>0.915488</td>\n","      <td>0.909590</td>\n","      <td>0.910788</td>\n","      <td>0.842836</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.003800</td>\n","      <td>0.033253</td>\n","      <td>0.923576</td>\n","      <td>0.924462</td>\n","      <td>0.923576</td>\n","      <td>0.923345</td>\n","      <td>0.864729</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.002700</td>\n","      <td>0.034914</td>\n","      <td>0.922577</td>\n","      <td>0.923851</td>\n","      <td>0.922577</td>\n","      <td>0.922797</td>\n","      <td>0.863883</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ Best model saved to /content/drive/MyDrive/RoBERTa_8_Results/glad-sweep-12/best_model\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▆▆█▇███</td></tr><tr><td>eval/f1</td><td>▁▆▆█████</td></tr><tr><td>eval/loss</td><td>█▂▂▁▁▁▁▁</td></tr><tr><td>eval/mcc</td><td>▁▆▆█▇███</td></tr><tr><td>eval/precision</td><td>▁▇▇█████</td></tr><tr><td>eval/recall</td><td>▁▆▆█▇███</td></tr><tr><td>eval/runtime</td><td>▁▃▇▃██▅▇</td></tr><tr><td>eval/samples_per_second</td><td>█▆▂▆▁▁▄▂</td></tr><tr><td>eval/steps_per_second</td><td>█▆▂▆▁▁▄▂</td></tr><tr><td>eval_accuracy</td><td>▁</td></tr><tr><td>eval_f1</td><td>▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_mcc</td><td>▁</td></tr><tr><td>eval_precision</td><td>▁</td></tr><tr><td>eval_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/mcc</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▅▅▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▅▅▆▆▇▇██████</td></tr><tr><td>train/grad_norm</td><td>▆██▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▆█▇▆▅▃▁</td></tr><tr><td>train/loss</td><td>█▃▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.91858</td></tr><tr><td>eval/f1</td><td>0.91656</td></tr><tr><td>eval/loss</td><td>0.03278</td></tr><tr><td>eval/mcc</td><td>0.85264</td></tr><tr><td>eval/precision</td><td>0.9179</td></tr><tr><td>eval/recall</td><td>0.91858</td></tr><tr><td>eval/runtime</td><td>0.9357</td></tr><tr><td>eval/samples_per_second</td><td>2139.564</td></tr><tr><td>eval/steps_per_second</td><td>67.329</td></tr><tr><td>eval_accuracy</td><td>0.91858</td></tr><tr><td>eval_f1</td><td>0.91656</td></tr><tr><td>eval_loss</td><td>0.03278</td></tr><tr><td>eval_mcc</td><td>0.85264</td></tr><tr><td>eval_precision</td><td>0.9179</td></tr><tr><td>eval_recall</td><td>0.91858</td></tr><tr><td>test/accuracy</td><td>0.91858</td></tr><tr><td>test/f1</td><td>0.91656</td></tr><tr><td>test/loss</td><td>0.03278</td></tr><tr><td>test/mcc</td><td>0.85264</td></tr><tr><td>test/precision</td><td>0.9179</td></tr><tr><td>test/recall</td><td>0.91858</td></tr><tr><td>test/runtime</td><td>1.0163</td></tr><tr><td>test/samples_per_second</td><td>1969.825</td></tr><tr><td>test/steps_per_second</td><td>61.987</td></tr><tr><td>total_flos</td><td>3340070550819072.0</td></tr><tr><td>train/epoch</td><td>7</td></tr><tr><td>train/global_step</td><td>882</td></tr><tr><td>train/grad_norm</td><td>0.02841</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.0027</td></tr><tr><td>train_loss</td><td>0.05227</td></tr><tr><td>train_runtime</td><td>140.4398</td></tr><tr><td>train_samples_per_second</td><td>683.909</td></tr><tr><td>train_steps_per_second</td><td>10.681</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">glad-sweep-12</strong> at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/4q85n5bj' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/4q85n5bj</a><br> View project at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250218_022513-4q85n5bj/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ls8yno1l with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.05467332123109417\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3.346220507668927e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_grad_norm: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 12\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.04379376304435993\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.6"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250218_022748-ls8yno1l</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/ls8yno1l' target=\"_blank\">sage-sweep-13</a></strong> to <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/ls8yno1l' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/ls8yno1l</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Total Steps: 756, Warmup Steps (10%): 75\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_grad_norm' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_train_epochs' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='441' max='744' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [441/744 02:17 < 01:34, 3.19 it/s, Epoch 7/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Mcc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.262900</td>\n","      <td>0.139075</td>\n","      <td>0.724276</td>\n","      <td>0.792799</td>\n","      <td>0.724276</td>\n","      <td>0.725767</td>\n","      <td>0.542163</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.065300</td>\n","      <td>0.042453</td>\n","      <td>0.870130</td>\n","      <td>0.883235</td>\n","      <td>0.870130</td>\n","      <td>0.873458</td>\n","      <td>0.775708</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.026200</td>\n","      <td>0.034891</td>\n","      <td>0.898102</td>\n","      <td>0.908435</td>\n","      <td>0.898102</td>\n","      <td>0.900535</td>\n","      <td>0.821759</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.012800</td>\n","      <td>0.030577</td>\n","      <td>0.918581</td>\n","      <td>0.920000</td>\n","      <td>0.918581</td>\n","      <td>0.917583</td>\n","      <td>0.853861</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.005300</td>\n","      <td>0.033752</td>\n","      <td>0.920080</td>\n","      <td>0.922038</td>\n","      <td>0.920080</td>\n","      <td>0.918483</td>\n","      <td>0.857252</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.003100</td>\n","      <td>0.031372</td>\n","      <td>0.921578</td>\n","      <td>0.923513</td>\n","      <td>0.921578</td>\n","      <td>0.922318</td>\n","      <td>0.862252</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.001500</td>\n","      <td>0.032800</td>\n","      <td>0.925075</td>\n","      <td>0.926245</td>\n","      <td>0.925075</td>\n","      <td>0.925449</td>\n","      <td>0.867827</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ Best model saved to /content/drive/MyDrive/RoBERTa_8_Results/sage-sweep-13/best_model\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▆▇█████</td></tr><tr><td>eval/f1</td><td>▁▆▇█████</td></tr><tr><td>eval/loss</td><td>█▂▁▁▁▁▁▁</td></tr><tr><td>eval/mcc</td><td>▁▆▇█████</td></tr><tr><td>eval/precision</td><td>▁▆▇█████</td></tr><tr><td>eval/recall</td><td>▁▆▇█████</td></tr><tr><td>eval/runtime</td><td>█▄▇▄▁▂▂▅</td></tr><tr><td>eval/samples_per_second</td><td>▁▅▁▅█▇▇▄</td></tr><tr><td>eval/steps_per_second</td><td>▁▅▁▅█▇▇▄</td></tr><tr><td>eval_accuracy</td><td>▁</td></tr><tr><td>eval_f1</td><td>▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_mcc</td><td>▁</td></tr><tr><td>eval_precision</td><td>▁</td></tr><tr><td>eval_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/mcc</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▅▅▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▅▅▆▆▇▇██████</td></tr><tr><td>train/grad_norm</td><td>▆▂█▃▁▂▂</td></tr><tr><td>train/learning_rate</td><td>▆█▇▆▅▃▁</td></tr><tr><td>train/loss</td><td>█▃▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.91858</td></tr><tr><td>eval/f1</td><td>0.91758</td></tr><tr><td>eval/loss</td><td>0.03058</td></tr><tr><td>eval/mcc</td><td>0.85386</td></tr><tr><td>eval/precision</td><td>0.92</td></tr><tr><td>eval/recall</td><td>0.91858</td></tr><tr><td>eval/runtime</td><td>0.9267</td></tr><tr><td>eval/samples_per_second</td><td>2160.325</td></tr><tr><td>eval/steps_per_second</td><td>67.982</td></tr><tr><td>eval_accuracy</td><td>0.91858</td></tr><tr><td>eval_f1</td><td>0.91758</td></tr><tr><td>eval_loss</td><td>0.03058</td></tr><tr><td>eval_mcc</td><td>0.85386</td></tr><tr><td>eval_precision</td><td>0.92</td></tr><tr><td>eval_recall</td><td>0.91858</td></tr><tr><td>test/accuracy</td><td>0.91858</td></tr><tr><td>test/f1</td><td>0.91758</td></tr><tr><td>test/loss</td><td>0.03058</td></tr><tr><td>test/mcc</td><td>0.85386</td></tr><tr><td>test/precision</td><td>0.92</td></tr><tr><td>test/recall</td><td>0.91858</td></tr><tr><td>test/runtime</td><td>1.0223</td></tr><tr><td>test/samples_per_second</td><td>1958.275</td></tr><tr><td>test/steps_per_second</td><td>61.624</td></tr><tr><td>total_flos</td><td>3340070550819072.0</td></tr><tr><td>train/epoch</td><td>7</td></tr><tr><td>train/global_step</td><td>441</td></tr><tr><td>train/grad_norm</td><td>0.51091</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.0015</td></tr><tr><td>train_loss</td><td>0.05388</td></tr><tr><td>train_runtime</td><td>137.8503</td></tr><tr><td>train_samples_per_second</td><td>696.756</td></tr><tr><td>train_steps_per_second</td><td>5.397</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">sage-sweep-13</strong> at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/ls8yno1l' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/ls8yno1l</a><br> View project at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250218_022748-ls8yno1l/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: j1bak48d with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.05075967285023596\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.8632073013105667e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_grad_norm: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 12\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.04717317903623568\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.6"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250218_023020-j1bak48d</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/j1bak48d' target=\"_blank\">toasty-sweep-14</a></strong> to <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/j1bak48d' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/j1bak48d</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Total Steps: 1512, Warmup Steps (10%): 151\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_grad_norm' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_train_epochs' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1260' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1260/1500 03:19 < 00:38, 6.31 it/s, Epoch 10/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Mcc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.240500</td>\n","      <td>0.086111</td>\n","      <td>0.817682</td>\n","      <td>0.799322</td>\n","      <td>0.817682</td>\n","      <td>0.806744</td>\n","      <td>0.677111</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.051200</td>\n","      <td>0.036587</td>\n","      <td>0.897103</td>\n","      <td>0.900964</td>\n","      <td>0.897103</td>\n","      <td>0.897083</td>\n","      <td>0.818791</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.021900</td>\n","      <td>0.040578</td>\n","      <td>0.892607</td>\n","      <td>0.903480</td>\n","      <td>0.892607</td>\n","      <td>0.894841</td>\n","      <td>0.817091</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.011000</td>\n","      <td>0.034610</td>\n","      <td>0.917083</td>\n","      <td>0.916269</td>\n","      <td>0.917083</td>\n","      <td>0.913971</td>\n","      <td>0.849240</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.005100</td>\n","      <td>0.034995</td>\n","      <td>0.917582</td>\n","      <td>0.921111</td>\n","      <td>0.917582</td>\n","      <td>0.917193</td>\n","      <td>0.853238</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.002300</td>\n","      <td>0.032232</td>\n","      <td>0.926573</td>\n","      <td>0.925594</td>\n","      <td>0.926573</td>\n","      <td>0.925569</td>\n","      <td>0.868239</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.001300</td>\n","      <td>0.031771</td>\n","      <td>0.927572</td>\n","      <td>0.927592</td>\n","      <td>0.927572</td>\n","      <td>0.927420</td>\n","      <td>0.871202</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.000600</td>\n","      <td>0.033863</td>\n","      <td>0.924076</td>\n","      <td>0.925354</td>\n","      <td>0.924076</td>\n","      <td>0.924463</td>\n","      <td>0.865970</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.000300</td>\n","      <td>0.034451</td>\n","      <td>0.925075</td>\n","      <td>0.926282</td>\n","      <td>0.925075</td>\n","      <td>0.925459</td>\n","      <td>0.867739</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.000300</td>\n","      <td>0.034113</td>\n","      <td>0.924575</td>\n","      <td>0.926119</td>\n","      <td>0.924575</td>\n","      <td>0.925166</td>\n","      <td>0.867069</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ Best model saved to /content/drive/MyDrive/RoBERTa_8_Results/toasty-sweep-14/best_model\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▆▆▇▇██████</td></tr><tr><td>eval/f1</td><td>▁▆▆▇▇██████</td></tr><tr><td>eval/loss</td><td>█▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/mcc</td><td>▁▆▆▇▇██████</td></tr><tr><td>eval/precision</td><td>▁▇▇▇███████</td></tr><tr><td>eval/recall</td><td>▁▆▆▇▇██████</td></tr><tr><td>eval/runtime</td><td>▂▄▁▄▃▁▅▂▆▃█</td></tr><tr><td>eval/samples_per_second</td><td>▇▅█▅▆█▄▇▃▆▁</td></tr><tr><td>eval/steps_per_second</td><td>▇▅█▅▆█▄▇▃▆▁</td></tr><tr><td>eval_accuracy</td><td>▁</td></tr><tr><td>eval_f1</td><td>▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_mcc</td><td>▁</td></tr><tr><td>eval_precision</td><td>▁</td></tr><tr><td>eval_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/mcc</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇██████</td></tr><tr><td>train/grad_norm</td><td>█▇▅▁▁▁▆▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▇██▇▆▅▄▃▂▁</td></tr><tr><td>train/loss</td><td>█▂▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.92757</td></tr><tr><td>eval/f1</td><td>0.92742</td></tr><tr><td>eval/loss</td><td>0.03177</td></tr><tr><td>eval/mcc</td><td>0.8712</td></tr><tr><td>eval/precision</td><td>0.92759</td></tr><tr><td>eval/recall</td><td>0.92757</td></tr><tr><td>eval/runtime</td><td>0.9865</td></tr><tr><td>eval/samples_per_second</td><td>2029.401</td></tr><tr><td>eval/steps_per_second</td><td>63.862</td></tr><tr><td>eval_accuracy</td><td>0.92757</td></tr><tr><td>eval_f1</td><td>0.92742</td></tr><tr><td>eval_loss</td><td>0.03177</td></tr><tr><td>eval_mcc</td><td>0.8712</td></tr><tr><td>eval_precision</td><td>0.92759</td></tr><tr><td>eval_recall</td><td>0.92757</td></tr><tr><td>test/accuracy</td><td>0.92757</td></tr><tr><td>test/f1</td><td>0.92742</td></tr><tr><td>test/loss</td><td>0.03177</td></tr><tr><td>test/mcc</td><td>0.8712</td></tr><tr><td>test/precision</td><td>0.92759</td></tr><tr><td>test/recall</td><td>0.92757</td></tr><tr><td>test/runtime</td><td>1.0258</td></tr><tr><td>test/samples_per_second</td><td>1951.676</td></tr><tr><td>test/steps_per_second</td><td>61.416</td></tr><tr><td>total_flos</td><td>4771529358312960.0</td></tr><tr><td>train/epoch</td><td>10</td></tr><tr><td>train/global_step</td><td>1260</td></tr><tr><td>train/grad_norm</td><td>0.02651</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0003</td></tr><tr><td>train_loss</td><td>0.03348</td></tr><tr><td>train_runtime</td><td>199.4179</td></tr><tr><td>train_samples_per_second</td><td>481.642</td></tr><tr><td>train_steps_per_second</td><td>7.522</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">toasty-sweep-14</strong> at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/j1bak48d' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/j1bak48d</a><br> View project at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250218_023020-j1bak48d/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xvf0rdfk with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.06730348337514822\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.4490559351618888e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_grad_norm: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 12\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0488772621686708\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.6"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250218_023354-xvf0rdfk</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/xvf0rdfk' target=\"_blank\">solar-sweep-15</a></strong> to <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/xvf0rdfk' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/xvf0rdfk</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Total Steps: 1512, Warmup Steps (10%): 151\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_grad_norm' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_train_epochs' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1260' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1260/1500 03:20 < 00:38, 6.26 it/s, Epoch 10/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Mcc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.259600</td>\n","      <td>0.097498</td>\n","      <td>0.807692</td>\n","      <td>0.828412</td>\n","      <td>0.807692</td>\n","      <td>0.811738</td>\n","      <td>0.677129</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.054100</td>\n","      <td>0.038527</td>\n","      <td>0.883117</td>\n","      <td>0.892921</td>\n","      <td>0.883117</td>\n","      <td>0.886533</td>\n","      <td>0.801071</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.024800</td>\n","      <td>0.040235</td>\n","      <td>0.888611</td>\n","      <td>0.899240</td>\n","      <td>0.888611</td>\n","      <td>0.890447</td>\n","      <td>0.809188</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.013000</td>\n","      <td>0.032955</td>\n","      <td>0.916084</td>\n","      <td>0.915344</td>\n","      <td>0.916084</td>\n","      <td>0.914068</td>\n","      <td>0.848493</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.007300</td>\n","      <td>0.038983</td>\n","      <td>0.902597</td>\n","      <td>0.912105</td>\n","      <td>0.902597</td>\n","      <td>0.905232</td>\n","      <td>0.835916</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.004400</td>\n","      <td>0.035247</td>\n","      <td>0.917083</td>\n","      <td>0.918521</td>\n","      <td>0.917083</td>\n","      <td>0.916402</td>\n","      <td>0.852683</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.003000</td>\n","      <td>0.031723</td>\n","      <td>0.923077</td>\n","      <td>0.923122</td>\n","      <td>0.923077</td>\n","      <td>0.922964</td>\n","      <td>0.863360</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.001900</td>\n","      <td>0.034269</td>\n","      <td>0.922577</td>\n","      <td>0.923761</td>\n","      <td>0.922577</td>\n","      <td>0.922933</td>\n","      <td>0.863763</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.001300</td>\n","      <td>0.033765</td>\n","      <td>0.923576</td>\n","      <td>0.924171</td>\n","      <td>0.923576</td>\n","      <td>0.923678</td>\n","      <td>0.864805</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.001100</td>\n","      <td>0.035042</td>\n","      <td>0.920579</td>\n","      <td>0.921760</td>\n","      <td>0.920579</td>\n","      <td>0.920975</td>\n","      <td>0.860240</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ Best model saved to /content/drive/MyDrive/RoBERTa_8_Results/solar-sweep-15/best_model\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▆▆█▇██████</td></tr><tr><td>eval/f1</td><td>▁▆▆▇▇██████</td></tr><tr><td>eval/loss</td><td>█▂▂▁▂▁▁▁▁▁▁</td></tr><tr><td>eval/mcc</td><td>▁▆▆▇▇██████</td></tr><tr><td>eval/precision</td><td>▁▆▆▇▇██████</td></tr><tr><td>eval/recall</td><td>▁▆▆█▇██████</td></tr><tr><td>eval/runtime</td><td>▃▁▂▆▂▃▂▄▆█▇</td></tr><tr><td>eval/samples_per_second</td><td>▆█▇▃▇▆▇▅▃▁▂</td></tr><tr><td>eval/steps_per_second</td><td>▆█▇▃▇▆▇▅▃▁▂</td></tr><tr><td>eval_accuracy</td><td>▁</td></tr><tr><td>eval_f1</td><td>▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_mcc</td><td>▁</td></tr><tr><td>eval_precision</td><td>▁</td></tr><tr><td>eval_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/mcc</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇██████</td></tr><tr><td>train/grad_norm</td><td>█▄▂▂▂▄▂▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▇██▇▆▅▄▃▂▁</td></tr><tr><td>train/loss</td><td>█▂▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.92308</td></tr><tr><td>eval/f1</td><td>0.92296</td></tr><tr><td>eval/loss</td><td>0.03172</td></tr><tr><td>eval/mcc</td><td>0.86336</td></tr><tr><td>eval/precision</td><td>0.92312</td></tr><tr><td>eval/recall</td><td>0.92308</td></tr><tr><td>eval/runtime</td><td>0.9565</td></tr><tr><td>eval/samples_per_second</td><td>2093.103</td></tr><tr><td>eval/steps_per_second</td><td>65.867</td></tr><tr><td>eval_accuracy</td><td>0.92308</td></tr><tr><td>eval_f1</td><td>0.92296</td></tr><tr><td>eval_loss</td><td>0.03172</td></tr><tr><td>eval_mcc</td><td>0.86336</td></tr><tr><td>eval_precision</td><td>0.92312</td></tr><tr><td>eval_recall</td><td>0.92308</td></tr><tr><td>test/accuracy</td><td>0.92308</td></tr><tr><td>test/f1</td><td>0.92296</td></tr><tr><td>test/loss</td><td>0.03172</td></tr><tr><td>test/mcc</td><td>0.86336</td></tr><tr><td>test/precision</td><td>0.92312</td></tr><tr><td>test/recall</td><td>0.92308</td></tr><tr><td>test/runtime</td><td>1.0685</td></tr><tr><td>test/samples_per_second</td><td>1873.676</td></tr><tr><td>test/steps_per_second</td><td>58.962</td></tr><tr><td>total_flos</td><td>4771529358312960.0</td></tr><tr><td>train/epoch</td><td>10</td></tr><tr><td>train/global_step</td><td>1260</td></tr><tr><td>train/grad_norm</td><td>0.00547</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0011</td></tr><tr><td>train_loss</td><td>0.03705</td></tr><tr><td>train_runtime</td><td>201.0094</td></tr><tr><td>train_samples_per_second</td><td>477.829</td></tr><tr><td>train_steps_per_second</td><td>7.462</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">solar-sweep-15</strong> at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/xvf0rdfk' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/xvf0rdfk</a><br> View project at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250218_023354-xvf0rdfk/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ctqgt2sk with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.052695271144165744\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3.3021336840901344e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_grad_norm: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 12\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.04694540244636485\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.6"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250218_023732-ctqgt2sk</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/ctqgt2sk' target=\"_blank\">driven-sweep-16</a></strong> to <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/ctqgt2sk' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/ctqgt2sk</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Total Steps: 1512, Warmup Steps (10%): 151\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_grad_norm' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_train_epochs' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='756' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 756/1500 02:02 < 02:01, 6.14 it/s, Epoch 6/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Mcc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.204700</td>\n","      <td>0.059050</td>\n","      <td>0.845155</td>\n","      <td>0.863072</td>\n","      <td>0.845155</td>\n","      <td>0.848996</td>\n","      <td>0.741026</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.042100</td>\n","      <td>0.043270</td>\n","      <td>0.866633</td>\n","      <td>0.887843</td>\n","      <td>0.866633</td>\n","      <td>0.872165</td>\n","      <td>0.778721</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.020400</td>\n","      <td>0.033123</td>\n","      <td>0.910090</td>\n","      <td>0.914300</td>\n","      <td>0.910090</td>\n","      <td>0.910477</td>\n","      <td>0.842414</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.008400</td>\n","      <td>0.039184</td>\n","      <td>0.915584</td>\n","      <td>0.915903</td>\n","      <td>0.915584</td>\n","      <td>0.912160</td>\n","      <td>0.846529</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.004400</td>\n","      <td>0.038695</td>\n","      <td>0.910589</td>\n","      <td>0.917846</td>\n","      <td>0.910589</td>\n","      <td>0.912228</td>\n","      <td>0.845055</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.002700</td>\n","      <td>0.043012</td>\n","      <td>0.919580</td>\n","      <td>0.917977</td>\n","      <td>0.919580</td>\n","      <td>0.916730</td>\n","      <td>0.854545</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ Best model saved to /content/drive/MyDrive/RoBERTa_8_Results/driven-sweep-16/best_model\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▃▇█▇█▇</td></tr><tr><td>eval/f1</td><td>▁▃▇███▇</td></tr><tr><td>eval/loss</td><td>█▄▁▃▃▄▁</td></tr><tr><td>eval/mcc</td><td>▁▃▇█▇█▇</td></tr><tr><td>eval/precision</td><td>▁▄█████</td></tr><tr><td>eval/recall</td><td>▁▃▇█▇█▇</td></tr><tr><td>eval/runtime</td><td>▇▄█▁▆▅▆</td></tr><tr><td>eval/samples_per_second</td><td>▂▅▁█▃▄▂</td></tr><tr><td>eval/steps_per_second</td><td>▂▅▁█▃▄▂</td></tr><tr><td>eval_accuracy</td><td>▁</td></tr><tr><td>eval_f1</td><td>▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_mcc</td><td>▁</td></tr><tr><td>eval_precision</td><td>▁</td></tr><tr><td>eval_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/mcc</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▄▄▅▅▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▄▄▅▅▇▇██████</td></tr><tr><td>train/grad_norm</td><td>█▃▃▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▅█▇▅▃▁</td></tr><tr><td>train/loss</td><td>█▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.91009</td></tr><tr><td>eval/f1</td><td>0.91048</td></tr><tr><td>eval/loss</td><td>0.03312</td></tr><tr><td>eval/mcc</td><td>0.84241</td></tr><tr><td>eval/precision</td><td>0.9143</td></tr><tr><td>eval/recall</td><td>0.91009</td></tr><tr><td>eval/runtime</td><td>0.9677</td></tr><tr><td>eval/samples_per_second</td><td>2068.928</td></tr><tr><td>eval/steps_per_second</td><td>65.106</td></tr><tr><td>eval_accuracy</td><td>0.91009</td></tr><tr><td>eval_f1</td><td>0.91048</td></tr><tr><td>eval_loss</td><td>0.03312</td></tr><tr><td>eval_mcc</td><td>0.84241</td></tr><tr><td>eval_precision</td><td>0.9143</td></tr><tr><td>eval_recall</td><td>0.91009</td></tr><tr><td>test/accuracy</td><td>0.91009</td></tr><tr><td>test/f1</td><td>0.91048</td></tr><tr><td>test/loss</td><td>0.03312</td></tr><tr><td>test/mcc</td><td>0.84241</td></tr><tr><td>test/precision</td><td>0.9143</td></tr><tr><td>test/recall</td><td>0.91009</td></tr><tr><td>test/runtime</td><td>1.1166</td></tr><tr><td>test/samples_per_second</td><td>1792.962</td></tr><tr><td>test/steps_per_second</td><td>56.422</td></tr><tr><td>total_flos</td><td>2862917614987776.0</td></tr><tr><td>train/epoch</td><td>6</td></tr><tr><td>train/global_step</td><td>756</td></tr><tr><td>train/grad_norm</td><td>0.01054</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>0.0027</td></tr><tr><td>train_loss</td><td>0.04712</td></tr><tr><td>train_runtime</td><td>122.9198</td></tr><tr><td>train_samples_per_second</td><td>781.387</td></tr><tr><td>train_steps_per_second</td><td>12.203</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">driven-sweep-16</strong> at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/ctqgt2sk' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/ctqgt2sk</a><br> View project at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250218_023732-ctqgt2sk/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mx24mwmm with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1035657394236676\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2.785763476289485e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_grad_norm: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 12\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.048936060271168966\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.6"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250218_023950-mx24mwmm</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/mx24mwmm' target=\"_blank\">golden-sweep-17</a></strong> to <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/mx24mwmm' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/mx24mwmm</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Total Steps: 1512, Warmup Steps (10%): 151\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_grad_norm' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_train_epochs' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='882' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 882/1500 02:22 < 01:40, 6.16 it/s, Epoch 7/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Mcc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.214700</td>\n","      <td>0.069708</td>\n","      <td>0.824176</td>\n","      <td>0.849721</td>\n","      <td>0.824176</td>\n","      <td>0.825077</td>\n","      <td>0.699382</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.048500</td>\n","      <td>0.050172</td>\n","      <td>0.840160</td>\n","      <td>0.877082</td>\n","      <td>0.840160</td>\n","      <td>0.849564</td>\n","      <td>0.751811</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.023700</td>\n","      <td>0.046954</td>\n","      <td>0.879121</td>\n","      <td>0.898303</td>\n","      <td>0.879121</td>\n","      <td>0.883578</td>\n","      <td>0.801060</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.014000</td>\n","      <td>0.034469</td>\n","      <td>0.914086</td>\n","      <td>0.913995</td>\n","      <td>0.914086</td>\n","      <td>0.911179</td>\n","      <td>0.844182</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.008000</td>\n","      <td>0.039257</td>\n","      <td>0.899101</td>\n","      <td>0.908594</td>\n","      <td>0.899101</td>\n","      <td>0.901163</td>\n","      <td>0.829466</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.004300</td>\n","      <td>0.035236</td>\n","      <td>0.915584</td>\n","      <td>0.917445</td>\n","      <td>0.915584</td>\n","      <td>0.914898</td>\n","      <td>0.850582</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.003000</td>\n","      <td>0.035205</td>\n","      <td>0.910090</td>\n","      <td>0.914863</td>\n","      <td>0.910090</td>\n","      <td>0.911637</td>\n","      <td>0.844833</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ Best model saved to /content/drive/MyDrive/RoBERTa_8_Results/golden-sweep-17/best_model\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▂▅█▇███</td></tr><tr><td>eval/f1</td><td>▁▃▆█▇███</td></tr><tr><td>eval/loss</td><td>█▄▃▁▂▁▁▁</td></tr><tr><td>eval/mcc</td><td>▁▃▆█▇███</td></tr><tr><td>eval/precision</td><td>▁▄▆█▇███</td></tr><tr><td>eval/recall</td><td>▁▂▅█▇███</td></tr><tr><td>eval/runtime</td><td>▁▁▂▄▂▂▃█</td></tr><tr><td>eval/samples_per_second</td><td>██▇▅▇▇▆▁</td></tr><tr><td>eval/steps_per_second</td><td>██▇▅▇▇▆▁</td></tr><tr><td>eval_accuracy</td><td>▁</td></tr><tr><td>eval_f1</td><td>▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_mcc</td><td>▁</td></tr><tr><td>eval_precision</td><td>▁</td></tr><tr><td>eval_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/mcc</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▅▅▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▅▅▆▆▇▇██████</td></tr><tr><td>train/grad_norm</td><td>▃▃█▂▁▁▃</td></tr><tr><td>train/learning_rate</td><td>▆█▇▆▅▃▁</td></tr><tr><td>train/loss</td><td>█▃▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.91409</td></tr><tr><td>eval/f1</td><td>0.91118</td></tr><tr><td>eval/loss</td><td>0.03447</td></tr><tr><td>eval/mcc</td><td>0.84418</td></tr><tr><td>eval/precision</td><td>0.91399</td></tr><tr><td>eval/recall</td><td>0.91409</td></tr><tr><td>eval/runtime</td><td>1.0057</td></tr><tr><td>eval/samples_per_second</td><td>1990.686</td></tr><tr><td>eval/steps_per_second</td><td>62.644</td></tr><tr><td>eval_accuracy</td><td>0.91409</td></tr><tr><td>eval_f1</td><td>0.91118</td></tr><tr><td>eval_loss</td><td>0.03447</td></tr><tr><td>eval_mcc</td><td>0.84418</td></tr><tr><td>eval_precision</td><td>0.91399</td></tr><tr><td>eval_recall</td><td>0.91409</td></tr><tr><td>test/accuracy</td><td>0.91409</td></tr><tr><td>test/f1</td><td>0.91118</td></tr><tr><td>test/loss</td><td>0.03447</td></tr><tr><td>test/mcc</td><td>0.84418</td></tr><tr><td>test/precision</td><td>0.91399</td></tr><tr><td>test/recall</td><td>0.91409</td></tr><tr><td>test/runtime</td><td>1.0956</td></tr><tr><td>test/samples_per_second</td><td>1827.282</td></tr><tr><td>test/steps_per_second</td><td>57.502</td></tr><tr><td>total_flos</td><td>3340070550819072.0</td></tr><tr><td>train/epoch</td><td>7</td></tr><tr><td>train/global_step</td><td>882</td></tr><tr><td>train/grad_norm</td><td>1.93251</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.003</td></tr><tr><td>train_loss</td><td>0.04518</td></tr><tr><td>train_runtime</td><td>142.9994</td></tr><tr><td>train_samples_per_second</td><td>671.667</td></tr><tr><td>train_steps_per_second</td><td>10.49</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">golden-sweep-17</strong> at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/mx24mwmm' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/mx24mwmm</a><br> View project at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250218_023950-mx24mwmm/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8en3qhh4 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.07248160920660092\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 4.2621055083395145e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_grad_norm: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 12\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.049285287705257544\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.6"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250218_024228-8en3qhh4</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/8en3qhh4' target=\"_blank\">fiery-sweep-18</a></strong> to <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/8en3qhh4' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/8en3qhh4</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Total Steps: 3012, Warmup Steps (10%): 301\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_grad_norm' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_train_epochs' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1757' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1757/3000 04:24 < 03:07, 6.62 it/s, Epoch 7/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Mcc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.164200</td>\n","      <td>0.054036</td>\n","      <td>0.860639</td>\n","      <td>0.863703</td>\n","      <td>0.860639</td>\n","      <td>0.853951</td>\n","      <td>0.746276</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.041600</td>\n","      <td>0.042344</td>\n","      <td>0.877123</td>\n","      <td>0.893199</td>\n","      <td>0.877123</td>\n","      <td>0.880956</td>\n","      <td>0.790007</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.018900</td>\n","      <td>0.038819</td>\n","      <td>0.897103</td>\n","      <td>0.903577</td>\n","      <td>0.897103</td>\n","      <td>0.898583</td>\n","      <td>0.823532</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.009700</td>\n","      <td>0.034751</td>\n","      <td>0.924076</td>\n","      <td>0.926202</td>\n","      <td>0.924076</td>\n","      <td>0.924133</td>\n","      <td>0.865844</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.005200</td>\n","      <td>0.038308</td>\n","      <td>0.916084</td>\n","      <td>0.917465</td>\n","      <td>0.916084</td>\n","      <td>0.915885</td>\n","      <td>0.849763</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.003300</td>\n","      <td>0.041603</td>\n","      <td>0.921079</td>\n","      <td>0.919056</td>\n","      <td>0.921079</td>\n","      <td>0.919140</td>\n","      <td>0.857218</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.002000</td>\n","      <td>0.040609</td>\n","      <td>0.920579</td>\n","      <td>0.921369</td>\n","      <td>0.920579</td>\n","      <td>0.919506</td>\n","      <td>0.857792</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ Best model saved to /content/drive/MyDrive/RoBERTa_8_Results/fiery-sweep-18/best_model\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▃▅█▇███</td></tr><tr><td>eval/f1</td><td>▁▄▅█▇███</td></tr><tr><td>eval/loss</td><td>█▄▂▁▂▃▃▁</td></tr><tr><td>eval/mcc</td><td>▁▄▆█▇▇██</td></tr><tr><td>eval/precision</td><td>▁▄▅█▇▇▇█</td></tr><tr><td>eval/recall</td><td>▁▃▅█▇███</td></tr><tr><td>eval/runtime</td><td>▁▁▁▃▃▂▂█</td></tr><tr><td>eval/samples_per_second</td><td>███▆▆▆▇▁</td></tr><tr><td>eval/steps_per_second</td><td>███▆▆▆▇▁</td></tr><tr><td>eval_accuracy</td><td>▁</td></tr><tr><td>eval_f1</td><td>▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_mcc</td><td>▁</td></tr><tr><td>eval_precision</td><td>▁</td></tr><tr><td>eval_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/mcc</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▅▅▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▅▅▆▆▇▇██████</td></tr><tr><td>train/grad_norm</td><td>▂██▁▁█▁</td></tr><tr><td>train/learning_rate</td><td>▆█▇▆▅▃▁</td></tr><tr><td>train/loss</td><td>█▃▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.92408</td></tr><tr><td>eval/f1</td><td>0.92413</td></tr><tr><td>eval/loss</td><td>0.03475</td></tr><tr><td>eval/mcc</td><td>0.86584</td></tr><tr><td>eval/precision</td><td>0.9262</td></tr><tr><td>eval/recall</td><td>0.92408</td></tr><tr><td>eval/runtime</td><td>2.0028</td></tr><tr><td>eval/samples_per_second</td><td>999.601</td></tr><tr><td>eval/steps_per_second</td><td>62.912</td></tr><tr><td>eval_accuracy</td><td>0.92408</td></tr><tr><td>eval_f1</td><td>0.92413</td></tr><tr><td>eval_loss</td><td>0.03475</td></tr><tr><td>eval_mcc</td><td>0.86584</td></tr><tr><td>eval_precision</td><td>0.9262</td></tr><tr><td>eval_recall</td><td>0.92408</td></tr><tr><td>test/accuracy</td><td>0.92408</td></tr><tr><td>test/f1</td><td>0.92413</td></tr><tr><td>test/loss</td><td>0.03475</td></tr><tr><td>test/mcc</td><td>0.86584</td></tr><tr><td>test/precision</td><td>0.9262</td></tr><tr><td>test/recall</td><td>0.92408</td></tr><tr><td>test/runtime</td><td>2.149</td></tr><tr><td>test/samples_per_second</td><td>931.616</td></tr><tr><td>test/steps_per_second</td><td>58.633</td></tr><tr><td>total_flos</td><td>3340070550819072.0</td></tr><tr><td>train/epoch</td><td>7</td></tr><tr><td>train/global_step</td><td>1757</td></tr><tr><td>train/grad_norm</td><td>0.00015</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>0.002</td></tr><tr><td>train_loss</td><td>0.03499</td></tr><tr><td>train_runtime</td><td>265.1654</td></tr><tr><td>train_samples_per_second</td><td>362.219</td></tr><tr><td>train_steps_per_second</td><td>11.314</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">fiery-sweep-18</strong> at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/8en3qhh4' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/8en3qhh4</a><br> View project at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250218_024228-8en3qhh4/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0ylcbykd with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.053089155048262233\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2.0239732672156662e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_grad_norm: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 12\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.040384193068281435\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.6"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250218_024707-0ylcbykd</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/0ylcbykd' target=\"_blank\">dark-sweep-19</a></strong> to <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/0ylcbykd' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/0ylcbykd</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Total Steps: 1512, Warmup Steps (10%): 151\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_grad_norm' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_train_epochs' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1008' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1008/1500 02:39 < 01:18, 6.31 it/s, Epoch 8/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Mcc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.235800</td>\n","      <td>0.104435</td>\n","      <td>0.771728</td>\n","      <td>0.824052</td>\n","      <td>0.771728</td>\n","      <td>0.781822</td>\n","      <td>0.630775</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.053000</td>\n","      <td>0.037507</td>\n","      <td>0.892607</td>\n","      <td>0.894923</td>\n","      <td>0.892607</td>\n","      <td>0.892444</td>\n","      <td>0.808905</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.022300</td>\n","      <td>0.041818</td>\n","      <td>0.887612</td>\n","      <td>0.901308</td>\n","      <td>0.887612</td>\n","      <td>0.889674</td>\n","      <td>0.806700</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.011700</td>\n","      <td>0.033707</td>\n","      <td>0.923576</td>\n","      <td>0.922956</td>\n","      <td>0.923576</td>\n","      <td>0.921376</td>\n","      <td>0.861575</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.005600</td>\n","      <td>0.032347</td>\n","      <td>0.923576</td>\n","      <td>0.923883</td>\n","      <td>0.923576</td>\n","      <td>0.922930</td>\n","      <td>0.863187</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.002600</td>\n","      <td>0.035663</td>\n","      <td>0.921578</td>\n","      <td>0.921957</td>\n","      <td>0.921578</td>\n","      <td>0.920632</td>\n","      <td>0.859974</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.001600</td>\n","      <td>0.033667</td>\n","      <td>0.924076</td>\n","      <td>0.925377</td>\n","      <td>0.924076</td>\n","      <td>0.924309</td>\n","      <td>0.865107</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.000800</td>\n","      <td>0.036266</td>\n","      <td>0.915085</td>\n","      <td>0.917889</td>\n","      <td>0.915085</td>\n","      <td>0.916137</td>\n","      <td>0.852034</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ Best model saved to /content/drive/MyDrive/RoBERTa_8_Results/dark-sweep-19/best_model\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▇▆██████</td></tr><tr><td>eval/f1</td><td>▁▆▆██████</td></tr><tr><td>eval/loss</td><td>█▂▂▁▁▁▁▁▁</td></tr><tr><td>eval/mcc</td><td>▁▆▆██████</td></tr><tr><td>eval/precision</td><td>▁▆▆████▇█</td></tr><tr><td>eval/recall</td><td>▁▇▆██████</td></tr><tr><td>eval/runtime</td><td>▄▁▅▆▇█▄▄▇</td></tr><tr><td>eval/samples_per_second</td><td>▅█▄▃▂▁▅▅▂</td></tr><tr><td>eval/steps_per_second</td><td>▅█▄▃▂▁▅▅▂</td></tr><tr><td>eval_accuracy</td><td>▁</td></tr><tr><td>eval_f1</td><td>▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_mcc</td><td>▁</td></tr><tr><td>eval_precision</td><td>▁</td></tr><tr><td>eval_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/mcc</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▇▇██████</td></tr><tr><td>train/grad_norm</td><td>█▄▄▁▁▃▁▁</td></tr><tr><td>train/learning_rate</td><td>▆█▇▇▅▄▂▁</td></tr><tr><td>train/loss</td><td>█▃▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.92358</td></tr><tr><td>eval/f1</td><td>0.92293</td></tr><tr><td>eval/loss</td><td>0.03235</td></tr><tr><td>eval/mcc</td><td>0.86319</td></tr><tr><td>eval/precision</td><td>0.92388</td></tr><tr><td>eval/recall</td><td>0.92358</td></tr><tr><td>eval/runtime</td><td>0.9288</td></tr><tr><td>eval/samples_per_second</td><td>2155.379</td></tr><tr><td>eval/steps_per_second</td><td>67.827</td></tr><tr><td>eval_accuracy</td><td>0.92358</td></tr><tr><td>eval_f1</td><td>0.92293</td></tr><tr><td>eval_loss</td><td>0.03235</td></tr><tr><td>eval_mcc</td><td>0.86319</td></tr><tr><td>eval_precision</td><td>0.92388</td></tr><tr><td>eval_recall</td><td>0.92358</td></tr><tr><td>test/accuracy</td><td>0.92358</td></tr><tr><td>test/f1</td><td>0.92293</td></tr><tr><td>test/loss</td><td>0.03235</td></tr><tr><td>test/mcc</td><td>0.86319</td></tr><tr><td>test/precision</td><td>0.92388</td></tr><tr><td>test/recall</td><td>0.92358</td></tr><tr><td>test/runtime</td><td>1.0307</td></tr><tr><td>test/samples_per_second</td><td>1942.427</td></tr><tr><td>test/steps_per_second</td><td>61.125</td></tr><tr><td>total_flos</td><td>3817223486650368.0</td></tr><tr><td>train/epoch</td><td>8</td></tr><tr><td>train/global_step</td><td>1008</td></tr><tr><td>train/grad_norm</td><td>0.0001</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.0008</td></tr><tr><td>train_loss</td><td>0.04167</td></tr><tr><td>train_runtime</td><td>159.6937</td></tr><tr><td>train_samples_per_second</td><td>601.451</td></tr><tr><td>train_steps_per_second</td><td>9.393</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">dark-sweep-19</strong> at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/0ylcbykd' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/0ylcbykd</a><br> View project at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250218_024707-0ylcbykd/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xwp4qpap with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.07903314515214156\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 4.385955264317498e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_grad_norm: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 12\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.049980818986872504\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.6"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250218_025003-xwp4qpap</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/xwp4qpap' target=\"_blank\">stellar-sweep-20</a></strong> to <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/xwp4qpap' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/xwp4qpap</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Total Steps: 1512, Warmup Steps (10%): 151\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_grad_norm' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_train_epochs' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='882' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 882/1500 02:20 < 01:38, 6.25 it/s, Epoch 7/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Mcc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.203600</td>\n","      <td>0.053376</td>\n","      <td>0.855644</td>\n","      <td>0.862195</td>\n","      <td>0.855644</td>\n","      <td>0.849202</td>\n","      <td>0.737499</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.042800</td>\n","      <td>0.041871</td>\n","      <td>0.873127</td>\n","      <td>0.887288</td>\n","      <td>0.873127</td>\n","      <td>0.876252</td>\n","      <td>0.786440</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.020800</td>\n","      <td>0.036918</td>\n","      <td>0.897103</td>\n","      <td>0.902491</td>\n","      <td>0.897103</td>\n","      <td>0.897939</td>\n","      <td>0.821146</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.010100</td>\n","      <td>0.031690</td>\n","      <td>0.922078</td>\n","      <td>0.922020</td>\n","      <td>0.922078</td>\n","      <td>0.921349</td>\n","      <td>0.860885</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.004700</td>\n","      <td>0.036751</td>\n","      <td>0.911588</td>\n","      <td>0.912916</td>\n","      <td>0.911588</td>\n","      <td>0.911529</td>\n","      <td>0.843208</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.003000</td>\n","      <td>0.036961</td>\n","      <td>0.916583</td>\n","      <td>0.917824</td>\n","      <td>0.916583</td>\n","      <td>0.916792</td>\n","      <td>0.852808</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.002300</td>\n","      <td>0.037669</td>\n","      <td>0.923077</td>\n","      <td>0.925468</td>\n","      <td>0.923077</td>\n","      <td>0.923618</td>\n","      <td>0.865384</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ Best model saved to /content/drive/MyDrive/RoBERTa_8_Results/stellar-sweep-20/best_model\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▃▅█▇▇██</td></tr><tr><td>eval/f1</td><td>▁▄▆█▇▇██</td></tr><tr><td>eval/loss</td><td>█▄▃▁▃▃▃▁</td></tr><tr><td>eval/mcc</td><td>▁▄▆█▇▇██</td></tr><tr><td>eval/precision</td><td>▁▄▅█▇▇██</td></tr><tr><td>eval/recall</td><td>▁▃▅█▇▇██</td></tr><tr><td>eval/runtime</td><td>▁▅▆▄█▇▄▆</td></tr><tr><td>eval/samples_per_second</td><td>█▄▂▅▁▂▄▃</td></tr><tr><td>eval/steps_per_second</td><td>█▄▂▅▁▂▄▃</td></tr><tr><td>eval_accuracy</td><td>▁</td></tr><tr><td>eval_f1</td><td>▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_mcc</td><td>▁</td></tr><tr><td>eval_precision</td><td>▁</td></tr><tr><td>eval_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/mcc</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▅▅▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▅▅▆▆▇▇██████</td></tr><tr><td>train/grad_norm</td><td>█▄▄▃▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▆█▇▆▅▃▁</td></tr><tr><td>train/loss</td><td>█▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.92208</td></tr><tr><td>eval/f1</td><td>0.92135</td></tr><tr><td>eval/loss</td><td>0.03169</td></tr><tr><td>eval/mcc</td><td>0.86089</td></tr><tr><td>eval/precision</td><td>0.92202</td></tr><tr><td>eval/recall</td><td>0.92208</td></tr><tr><td>eval/runtime</td><td>0.9235</td></tr><tr><td>eval/samples_per_second</td><td>2167.952</td></tr><tr><td>eval/steps_per_second</td><td>68.222</td></tr><tr><td>eval_accuracy</td><td>0.92208</td></tr><tr><td>eval_f1</td><td>0.92135</td></tr><tr><td>eval_loss</td><td>0.03169</td></tr><tr><td>eval_mcc</td><td>0.86089</td></tr><tr><td>eval_precision</td><td>0.92202</td></tr><tr><td>eval_recall</td><td>0.92208</td></tr><tr><td>test/accuracy</td><td>0.92208</td></tr><tr><td>test/f1</td><td>0.92135</td></tr><tr><td>test/loss</td><td>0.03169</td></tr><tr><td>test/mcc</td><td>0.86089</td></tr><tr><td>test/precision</td><td>0.92202</td></tr><tr><td>test/recall</td><td>0.92208</td></tr><tr><td>test/runtime</td><td>1.0715</td></tr><tr><td>test/samples_per_second</td><td>1868.35</td></tr><tr><td>test/steps_per_second</td><td>58.794</td></tr><tr><td>total_flos</td><td>3340070550819072.0</td></tr><tr><td>train/epoch</td><td>7</td></tr><tr><td>train/global_step</td><td>882</td></tr><tr><td>train/grad_norm</td><td>0.01495</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>0.0023</td></tr><tr><td>train_loss</td><td>0.04104</td></tr><tr><td>train_runtime</td><td>140.9473</td></tr><tr><td>train_samples_per_second</td><td>681.446</td></tr><tr><td>train_steps_per_second</td><td>10.642</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">stellar-sweep-20</strong> at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/xwp4qpap' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/xwp4qpap</a><br> View project at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250218_025003-xwp4qpap/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vvhvo5og with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.06492159882463382\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3.180349651909234e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_grad_norm: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 12\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.046257240290342054\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.6"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250218_025240-vvhvo5og</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/vvhvo5og' target=\"_blank\">genial-sweep-21</a></strong> to <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/vvhvo5og' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/vvhvo5og</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Total Steps: 1512, Warmup Steps (10%): 151\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_grad_norm' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_train_epochs' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1134' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1134/1500 03:00 < 00:58, 6.26 it/s, Epoch 9/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Mcc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.212300</td>\n","      <td>0.062686</td>\n","      <td>0.844655</td>\n","      <td>0.865794</td>\n","      <td>0.844655</td>\n","      <td>0.846369</td>\n","      <td>0.730053</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.043400</td>\n","      <td>0.038683</td>\n","      <td>0.894106</td>\n","      <td>0.900359</td>\n","      <td>0.894106</td>\n","      <td>0.893958</td>\n","      <td>0.813550</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.018900</td>\n","      <td>0.039206</td>\n","      <td>0.903596</td>\n","      <td>0.910920</td>\n","      <td>0.903596</td>\n","      <td>0.905304</td>\n","      <td>0.833257</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.009400</td>\n","      <td>0.034160</td>\n","      <td>0.928072</td>\n","      <td>0.928155</td>\n","      <td>0.928072</td>\n","      <td>0.926942</td>\n","      <td>0.870485</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.004400</td>\n","      <td>0.035702</td>\n","      <td>0.913586</td>\n","      <td>0.917636</td>\n","      <td>0.913586</td>\n","      <td>0.914914</td>\n","      <td>0.849232</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.002700</td>\n","      <td>0.033681</td>\n","      <td>0.924575</td>\n","      <td>0.926141</td>\n","      <td>0.924575</td>\n","      <td>0.925062</td>\n","      <td>0.867095</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.001600</td>\n","      <td>0.035333</td>\n","      <td>0.927572</td>\n","      <td>0.929770</td>\n","      <td>0.927572</td>\n","      <td>0.928211</td>\n","      <td>0.872211</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.000900</td>\n","      <td>0.035900</td>\n","      <td>0.927073</td>\n","      <td>0.929743</td>\n","      <td>0.927073</td>\n","      <td>0.927930</td>\n","      <td>0.872589</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.000400</td>\n","      <td>0.035410</td>\n","      <td>0.930569</td>\n","      <td>0.931443</td>\n","      <td>0.930569</td>\n","      <td>0.930827</td>\n","      <td>0.877112</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ Best model saved to /content/drive/MyDrive/RoBERTa_8_Results/genial-sweep-21/best_model\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▅▆█▇█████</td></tr><tr><td>eval/f1</td><td>▁▅▆█▇█████</td></tr><tr><td>eval/loss</td><td>█▂▂▁▁▁▁▂▁▁</td></tr><tr><td>eval/mcc</td><td>▁▅▆█▇█████</td></tr><tr><td>eval/precision</td><td>▁▅▆█▇▇███▇</td></tr><tr><td>eval/recall</td><td>▁▅▆█▇█████</td></tr><tr><td>eval/runtime</td><td>▂█▁▃▇▃█▂▆▅</td></tr><tr><td>eval/samples_per_second</td><td>▇▁█▆▂▆▁▇▃▄</td></tr><tr><td>eval/steps_per_second</td><td>▇▁█▆▂▆▁▇▃▄</td></tr><tr><td>eval_accuracy</td><td>▁</td></tr><tr><td>eval_f1</td><td>▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_mcc</td><td>▁</td></tr><tr><td>eval_precision</td><td>▁</td></tr><tr><td>eval_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/mcc</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▄▄▅▅▅▅▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▄▄▅▅▅▅▆▆▇▇██████</td></tr><tr><td>train/grad_norm</td><td>█▅▂▄▁▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▇██▇▆▅▃▂▁</td></tr><tr><td>train/loss</td><td>█▂▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.92458</td></tr><tr><td>eval/f1</td><td>0.92506</td></tr><tr><td>eval/loss</td><td>0.03368</td></tr><tr><td>eval/mcc</td><td>0.8671</td></tr><tr><td>eval/precision</td><td>0.92614</td></tr><tr><td>eval/recall</td><td>0.92458</td></tr><tr><td>eval/runtime</td><td>0.9409</td></tr><tr><td>eval/samples_per_second</td><td>2127.839</td></tr><tr><td>eval/steps_per_second</td><td>66.96</td></tr><tr><td>eval_accuracy</td><td>0.92458</td></tr><tr><td>eval_f1</td><td>0.92506</td></tr><tr><td>eval_loss</td><td>0.03368</td></tr><tr><td>eval_mcc</td><td>0.8671</td></tr><tr><td>eval_precision</td><td>0.92614</td></tr><tr><td>eval_recall</td><td>0.92458</td></tr><tr><td>test/accuracy</td><td>0.92458</td></tr><tr><td>test/f1</td><td>0.92506</td></tr><tr><td>test/loss</td><td>0.03368</td></tr><tr><td>test/mcc</td><td>0.8671</td></tr><tr><td>test/precision</td><td>0.92614</td></tr><tr><td>test/recall</td><td>0.92458</td></tr><tr><td>test/runtime</td><td>1.0397</td></tr><tr><td>test/samples_per_second</td><td>1925.621</td></tr><tr><td>test/steps_per_second</td><td>60.596</td></tr><tr><td>total_flos</td><td>4294376422481664.0</td></tr><tr><td>train/epoch</td><td>9</td></tr><tr><td>train/global_step</td><td>1134</td></tr><tr><td>train/grad_norm</td><td>0.07372</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.0004</td></tr><tr><td>train_loss</td><td>0.03266</td></tr><tr><td>train_runtime</td><td>180.8659</td></tr><tr><td>train_samples_per_second</td><td>531.045</td></tr><tr><td>train_steps_per_second</td><td>8.293</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">genial-sweep-21</strong> at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/vvhvo5og' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/vvhvo5og</a><br> View project at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250218_025240-vvhvo5og/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 543s29wo with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.05019595866903384\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3.380328217986513e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_grad_norm: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 12\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.04837406028360008\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.6"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250218_025603-543s29wo</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/543s29wo' target=\"_blank\">deft-sweep-22</a></strong> to <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/543s29wo' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/543s29wo</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Total Steps: 756, Warmup Steps (10%): 75\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_grad_norm' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_train_epochs' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='504' max='744' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [504/744 02:38 < 01:15, 3.16 it/s, Epoch 8/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Mcc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.253200</td>\n","      <td>0.126698</td>\n","      <td>0.762737</td>\n","      <td>0.796795</td>\n","      <td>0.762737</td>\n","      <td>0.759689</td>\n","      <td>0.587335</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.054400</td>\n","      <td>0.041557</td>\n","      <td>0.867632</td>\n","      <td>0.891977</td>\n","      <td>0.867632</td>\n","      <td>0.874109</td>\n","      <td>0.786264</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.022200</td>\n","      <td>0.032799</td>\n","      <td>0.906593</td>\n","      <td>0.912122</td>\n","      <td>0.906593</td>\n","      <td>0.907896</td>\n","      <td>0.835319</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.009500</td>\n","      <td>0.032923</td>\n","      <td>0.915584</td>\n","      <td>0.918687</td>\n","      <td>0.915584</td>\n","      <td>0.914271</td>\n","      <td>0.849964</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.004900</td>\n","      <td>0.031409</td>\n","      <td>0.919580</td>\n","      <td>0.921223</td>\n","      <td>0.919580</td>\n","      <td>0.919859</td>\n","      <td>0.857550</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.002300</td>\n","      <td>0.035497</td>\n","      <td>0.919081</td>\n","      <td>0.920994</td>\n","      <td>0.919081</td>\n","      <td>0.918249</td>\n","      <td>0.855999</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.001300</td>\n","      <td>0.033384</td>\n","      <td>0.928072</td>\n","      <td>0.929243</td>\n","      <td>0.928072</td>\n","      <td>0.928267</td>\n","      <td>0.873027</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.000600</td>\n","      <td>0.033748</td>\n","      <td>0.926074</td>\n","      <td>0.927233</td>\n","      <td>0.926074</td>\n","      <td>0.926390</td>\n","      <td>0.869660</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ Best model saved to /content/drive/MyDrive/RoBERTa_8_Results/deft-sweep-22/best_model\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▅▇▇█████</td></tr><tr><td>eval/f1</td><td>▁▆▇▇█████</td></tr><tr><td>eval/loss</td><td>█▂▁▁▁▁▁▁▁</td></tr><tr><td>eval/mcc</td><td>▁▆▇▇█████</td></tr><tr><td>eval/precision</td><td>▁▆▇▇█████</td></tr><tr><td>eval/recall</td><td>▁▅▇▇█████</td></tr><tr><td>eval/runtime</td><td>▄▃▁▁▇▃▅▆█</td></tr><tr><td>eval/samples_per_second</td><td>▅▆██▂▆▄▃▁</td></tr><tr><td>eval/steps_per_second</td><td>▅▆██▂▆▄▃▁</td></tr><tr><td>eval_accuracy</td><td>▁</td></tr><tr><td>eval_f1</td><td>▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_mcc</td><td>▁</td></tr><tr><td>eval_precision</td><td>▁</td></tr><tr><td>eval_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/mcc</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▇▇██████</td></tr><tr><td>train/grad_norm</td><td>▅▅▄█▄▂▂▁</td></tr><tr><td>train/learning_rate</td><td>▇█▇▇▅▄▂▁</td></tr><tr><td>train/loss</td><td>█▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.91958</td></tr><tr><td>eval/f1</td><td>0.91986</td></tr><tr><td>eval/loss</td><td>0.03141</td></tr><tr><td>eval/mcc</td><td>0.85755</td></tr><tr><td>eval/precision</td><td>0.92122</td></tr><tr><td>eval/recall</td><td>0.91958</td></tr><tr><td>eval/runtime</td><td>0.9431</td></tr><tr><td>eval/samples_per_second</td><td>2122.834</td></tr><tr><td>eval/steps_per_second</td><td>66.802</td></tr><tr><td>eval_accuracy</td><td>0.91958</td></tr><tr><td>eval_f1</td><td>0.91986</td></tr><tr><td>eval_loss</td><td>0.03141</td></tr><tr><td>eval_mcc</td><td>0.85755</td></tr><tr><td>eval_precision</td><td>0.92122</td></tr><tr><td>eval_recall</td><td>0.91958</td></tr><tr><td>test/accuracy</td><td>0.91958</td></tr><tr><td>test/f1</td><td>0.91986</td></tr><tr><td>test/loss</td><td>0.03141</td></tr><tr><td>test/mcc</td><td>0.85755</td></tr><tr><td>test/precision</td><td>0.92122</td></tr><tr><td>test/recall</td><td>0.91958</td></tr><tr><td>test/runtime</td><td>1.0601</td></tr><tr><td>test/samples_per_second</td><td>1888.587</td></tr><tr><td>test/steps_per_second</td><td>59.431</td></tr><tr><td>total_flos</td><td>3817223486650368.0</td></tr><tr><td>train/epoch</td><td>8</td></tr><tr><td>train/global_step</td><td>504</td></tr><tr><td>train/grad_norm</td><td>0.04795</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.0006</td></tr><tr><td>train_loss</td><td>0.04354</td></tr><tr><td>train_runtime</td><td>159.2325</td></tr><tr><td>train_samples_per_second</td><td>603.193</td></tr><tr><td>train_steps_per_second</td><td>4.672</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">deft-sweep-22</strong> at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/543s29wo' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/543s29wo</a><br> View project at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250218_025603-543s29wo/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ocbm92je with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.062057803733018946\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3.3986382689365755e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_grad_norm: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 12\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.044399555041597136\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.6"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250218_025856-ocbm92je</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/ocbm92je' target=\"_blank\">dulcet-sweep-23</a></strong> to <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/ocbm92je' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/ocbm92je</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Total Steps: 1512, Warmup Steps (10%): 151\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_grad_norm' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_train_epochs' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='756' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 756/1500 02:01 < 01:59, 6.23 it/s, Epoch 6/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Mcc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.208900</td>\n","      <td>0.066623</td>\n","      <td>0.819181</td>\n","      <td>0.850404</td>\n","      <td>0.819181</td>\n","      <td>0.823565</td>\n","      <td>0.700122</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.043500</td>\n","      <td>0.037756</td>\n","      <td>0.888112</td>\n","      <td>0.896980</td>\n","      <td>0.888112</td>\n","      <td>0.889131</td>\n","      <td>0.807066</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.021400</td>\n","      <td>0.032624</td>\n","      <td>0.909091</td>\n","      <td>0.911639</td>\n","      <td>0.909091</td>\n","      <td>0.909440</td>\n","      <td>0.840442</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.009800</td>\n","      <td>0.036198</td>\n","      <td>0.919580</td>\n","      <td>0.920241</td>\n","      <td>0.919580</td>\n","      <td>0.916816</td>\n","      <td>0.854244</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.004100</td>\n","      <td>0.041566</td>\n","      <td>0.905594</td>\n","      <td>0.913288</td>\n","      <td>0.905594</td>\n","      <td>0.907747</td>\n","      <td>0.838447</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.002500</td>\n","      <td>0.039099</td>\n","      <td>0.917582</td>\n","      <td>0.919347</td>\n","      <td>0.917582</td>\n","      <td>0.917952</td>\n","      <td>0.855506</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ Best model saved to /content/drive/MyDrive/RoBERTa_8_Results/dulcet-sweep-23/best_model\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▆▇█▇█▇</td></tr><tr><td>eval/f1</td><td>▁▆▇█▇█▇</td></tr><tr><td>eval/loss</td><td>█▂▁▂▃▂▁</td></tr><tr><td>eval/mcc</td><td>▁▆▇█▇█▇</td></tr><tr><td>eval/precision</td><td>▁▆▇█▇█▇</td></tr><tr><td>eval/recall</td><td>▁▆▇█▇█▇</td></tr><tr><td>eval/runtime</td><td>▁▁▂▁▅▁█</td></tr><tr><td>eval/samples_per_second</td><td>▇█▇█▄█▁</td></tr><tr><td>eval/steps_per_second</td><td>▇█▇█▄█▁</td></tr><tr><td>eval_accuracy</td><td>▁</td></tr><tr><td>eval_f1</td><td>▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_mcc</td><td>▁</td></tr><tr><td>eval_precision</td><td>▁</td></tr><tr><td>eval_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/mcc</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▄▄▅▅▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▄▄▅▅▇▇██████</td></tr><tr><td>train/grad_norm</td><td>█▆▃▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▅█▇▅▃▁</td></tr><tr><td>train/loss</td><td>█▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.90909</td></tr><tr><td>eval/f1</td><td>0.90944</td></tr><tr><td>eval/loss</td><td>0.03262</td></tr><tr><td>eval/mcc</td><td>0.84044</td></tr><tr><td>eval/precision</td><td>0.91164</td></tr><tr><td>eval/recall</td><td>0.90909</td></tr><tr><td>eval/runtime</td><td>0.9989</td></tr><tr><td>eval/samples_per_second</td><td>2004.258</td></tr><tr><td>eval/steps_per_second</td><td>63.071</td></tr><tr><td>eval_accuracy</td><td>0.90909</td></tr><tr><td>eval_f1</td><td>0.90944</td></tr><tr><td>eval_loss</td><td>0.03262</td></tr><tr><td>eval_mcc</td><td>0.84044</td></tr><tr><td>eval_precision</td><td>0.91164</td></tr><tr><td>eval_recall</td><td>0.90909</td></tr><tr><td>test/accuracy</td><td>0.90909</td></tr><tr><td>test/f1</td><td>0.90944</td></tr><tr><td>test/loss</td><td>0.03262</td></tr><tr><td>test/mcc</td><td>0.84044</td></tr><tr><td>test/precision</td><td>0.91164</td></tr><tr><td>test/recall</td><td>0.90909</td></tr><tr><td>test/runtime</td><td>1.0765</td></tr><tr><td>test/samples_per_second</td><td>1859.692</td></tr><tr><td>test/steps_per_second</td><td>58.522</td></tr><tr><td>total_flos</td><td>2862917614987776.0</td></tr><tr><td>train/epoch</td><td>6</td></tr><tr><td>train/global_step</td><td>756</td></tr><tr><td>train/grad_norm</td><td>0.01864</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>0.0025</td></tr><tr><td>train_loss</td><td>0.04836</td></tr><tr><td>train_runtime</td><td>121.2483</td></tr><tr><td>train_samples_per_second</td><td>792.159</td></tr><tr><td>train_steps_per_second</td><td>12.371</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">dulcet-sweep-23</strong> at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/ocbm92je' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/ocbm92je</a><br> View project at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250218_025856-ocbm92je/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: p9s7dh1e with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.09999953255487871\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3.281492601263243e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_grad_norm: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 12\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.04950702958236411\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.6"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250218_030113-p9s7dh1e</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/p9s7dh1e' target=\"_blank\">dainty-sweep-24</a></strong> to <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/p9s7dh1e' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/p9s7dh1e</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Total Steps: 1512, Warmup Steps (10%): 151\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_grad_norm' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_train_epochs' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='882' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 882/1500 02:20 < 01:38, 6.27 it/s, Epoch 7/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Mcc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.205200</td>\n","      <td>0.061254</td>\n","      <td>0.851648</td>\n","      <td>0.845625</td>\n","      <td>0.851648</td>\n","      <td>0.836110</td>\n","      <td>0.721863</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.043000</td>\n","      <td>0.043811</td>\n","      <td>0.869630</td>\n","      <td>0.890504</td>\n","      <td>0.869630</td>\n","      <td>0.874317</td>\n","      <td>0.785996</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.022800</td>\n","      <td>0.050441</td>\n","      <td>0.877123</td>\n","      <td>0.897405</td>\n","      <td>0.877123</td>\n","      <td>0.881533</td>\n","      <td>0.796000</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.011900</td>\n","      <td>0.035870</td>\n","      <td>0.919081</td>\n","      <td>0.920158</td>\n","      <td>0.919081</td>\n","      <td>0.916942</td>\n","      <td>0.854979</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.006500</td>\n","      <td>0.038755</td>\n","      <td>0.908092</td>\n","      <td>0.917861</td>\n","      <td>0.908092</td>\n","      <td>0.910958</td>\n","      <td>0.843549</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.004300</td>\n","      <td>0.037316</td>\n","      <td>0.923576</td>\n","      <td>0.924113</td>\n","      <td>0.923576</td>\n","      <td>0.922281</td>\n","      <td>0.863678</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.002400</td>\n","      <td>0.038020</td>\n","      <td>0.914585</td>\n","      <td>0.919738</td>\n","      <td>0.914585</td>\n","      <td>0.916131</td>\n","      <td>0.852730</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ Best model saved to /content/drive/MyDrive/RoBERTa_8_Results/dainty-sweep-24/best_model\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▃▃█▆█▇█</td></tr><tr><td>eval/f1</td><td>▁▄▅█▇███</td></tr><tr><td>eval/loss</td><td>█▃▅▁▂▁▂▁</td></tr><tr><td>eval/mcc</td><td>▁▄▅█▇█▇█</td></tr><tr><td>eval/precision</td><td>▁▅▆█▇███</td></tr><tr><td>eval/recall</td><td>▁▃▃█▆█▇█</td></tr><tr><td>eval/runtime</td><td>▆▆▁█▁▂▆▃</td></tr><tr><td>eval/samples_per_second</td><td>▃▃█▁█▇▃▆</td></tr><tr><td>eval/steps_per_second</td><td>▃▃█▁█▇▃▆</td></tr><tr><td>eval_accuracy</td><td>▁</td></tr><tr><td>eval_f1</td><td>▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_mcc</td><td>▁</td></tr><tr><td>eval_precision</td><td>▁</td></tr><tr><td>eval_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/mcc</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▅▅▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▅▅▆▆▇▇██████</td></tr><tr><td>train/grad_norm</td><td>▂█▃▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▆█▇▆▅▃▁</td></tr><tr><td>train/loss</td><td>█▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.91908</td></tr><tr><td>eval/f1</td><td>0.91694</td></tr><tr><td>eval/loss</td><td>0.03587</td></tr><tr><td>eval/mcc</td><td>0.85498</td></tr><tr><td>eval/precision</td><td>0.92016</td></tr><tr><td>eval/recall</td><td>0.91908</td></tr><tr><td>eval/runtime</td><td>0.9119</td></tr><tr><td>eval/samples_per_second</td><td>2195.357</td></tr><tr><td>eval/steps_per_second</td><td>69.085</td></tr><tr><td>eval_accuracy</td><td>0.91908</td></tr><tr><td>eval_f1</td><td>0.91694</td></tr><tr><td>eval_loss</td><td>0.03587</td></tr><tr><td>eval_mcc</td><td>0.85498</td></tr><tr><td>eval_precision</td><td>0.92016</td></tr><tr><td>eval_recall</td><td>0.91908</td></tr><tr><td>test/accuracy</td><td>0.91908</td></tr><tr><td>test/f1</td><td>0.91694</td></tr><tr><td>test/loss</td><td>0.03587</td></tr><tr><td>test/mcc</td><td>0.85498</td></tr><tr><td>test/precision</td><td>0.92016</td></tr><tr><td>test/recall</td><td>0.91908</td></tr><tr><td>test/runtime</td><td>1.0205</td></tr><tr><td>test/samples_per_second</td><td>1961.764</td></tr><tr><td>test/steps_per_second</td><td>61.734</td></tr><tr><td>total_flos</td><td>3340070550819072.0</td></tr><tr><td>train/epoch</td><td>7</td></tr><tr><td>train/global_step</td><td>882</td></tr><tr><td>train/grad_norm</td><td>0.17213</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.0024</td></tr><tr><td>train_loss</td><td>0.0423</td></tr><tr><td>train_runtime</td><td>140.4018</td></tr><tr><td>train_samples_per_second</td><td>684.094</td></tr><tr><td>train_steps_per_second</td><td>10.684</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">dainty-sweep-24</strong> at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/p9s7dh1e' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/p9s7dh1e</a><br> View project at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250218_030113-p9s7dh1e/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9j0j85v8 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.0958820653295907\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3.705605959842424e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_grad_norm: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 12\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.04617736828235132\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.6"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250218_030351-9j0j85v8</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/9j0j85v8' target=\"_blank\">happy-sweep-25</a></strong> to <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/9j0j85v8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/9j0j85v8</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Total Steps: 1512, Warmup Steps (10%): 151\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_grad_norm' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_train_epochs' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1260' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1260/1500 03:22 < 00:38, 6.21 it/s, Epoch 10/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Mcc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.210000</td>\n","      <td>0.055316</td>\n","      <td>0.855644</td>\n","      <td>0.866623</td>\n","      <td>0.855644</td>\n","      <td>0.851479</td>\n","      <td>0.742174</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.048600</td>\n","      <td>0.046864</td>\n","      <td>0.849151</td>\n","      <td>0.884458</td>\n","      <td>0.849151</td>\n","      <td>0.859038</td>\n","      <td>0.759799</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.024600</td>\n","      <td>0.043854</td>\n","      <td>0.884615</td>\n","      <td>0.899043</td>\n","      <td>0.884615</td>\n","      <td>0.888122</td>\n","      <td>0.806676</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.012500</td>\n","      <td>0.040100</td>\n","      <td>0.920579</td>\n","      <td>0.919975</td>\n","      <td>0.920579</td>\n","      <td>0.917827</td>\n","      <td>0.855736</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.007000</td>\n","      <td>0.047425</td>\n","      <td>0.899600</td>\n","      <td>0.909283</td>\n","      <td>0.899600</td>\n","      <td>0.902064</td>\n","      <td>0.828647</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.004300</td>\n","      <td>0.040555</td>\n","      <td>0.915584</td>\n","      <td>0.918606</td>\n","      <td>0.915584</td>\n","      <td>0.915175</td>\n","      <td>0.850693</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.002700</td>\n","      <td>0.037171</td>\n","      <td>0.916583</td>\n","      <td>0.919587</td>\n","      <td>0.916583</td>\n","      <td>0.917346</td>\n","      <td>0.854545</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.001300</td>\n","      <td>0.039354</td>\n","      <td>0.918581</td>\n","      <td>0.922687</td>\n","      <td>0.918581</td>\n","      <td>0.919970</td>\n","      <td>0.858483</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.000600</td>\n","      <td>0.037799</td>\n","      <td>0.929071</td>\n","      <td>0.929660</td>\n","      <td>0.929071</td>\n","      <td>0.929162</td>\n","      <td>0.874469</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.000400</td>\n","      <td>0.039072</td>\n","      <td>0.919081</td>\n","      <td>0.922438</td>\n","      <td>0.919081</td>\n","      <td>0.920228</td>\n","      <td>0.858973</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ Best model saved to /content/drive/MyDrive/RoBERTa_8_Results/happy-sweep-25/best_model\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▂▁▄▇▅▇▇▇█▇▇</td></tr><tr><td>eval/f1</td><td>▁▂▄▇▆▇▇▇█▇▇</td></tr><tr><td>eval/loss</td><td>█▅▄▂▅▂▁▂▁▂▁</td></tr><tr><td>eval/mcc</td><td>▁▂▄▇▆▇▇▇█▇▇</td></tr><tr><td>eval/precision</td><td>▁▃▅▇▆▇▇▇█▇▇</td></tr><tr><td>eval/recall</td><td>▂▁▄▇▅▇▇▇█▇▇</td></tr><tr><td>eval/runtime</td><td>█▃▁▅▅▇▅▃▇▇▆</td></tr><tr><td>eval/samples_per_second</td><td>▁▆█▄▄▂▄▆▂▂▃</td></tr><tr><td>eval/steps_per_second</td><td>▁▆█▄▄▂▄▆▂▂▃</td></tr><tr><td>eval_accuracy</td><td>▁</td></tr><tr><td>eval_f1</td><td>▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_mcc</td><td>▁</td></tr><tr><td>eval_precision</td><td>▁</td></tr><tr><td>eval_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/mcc</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇██████</td></tr><tr><td>train/grad_norm</td><td>▇█▇▁▁▂▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▇██▇▆▅▄▃▂▁</td></tr><tr><td>train/loss</td><td>█▃▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.91658</td></tr><tr><td>eval/f1</td><td>0.91735</td></tr><tr><td>eval/loss</td><td>0.03717</td></tr><tr><td>eval/mcc</td><td>0.85455</td></tr><tr><td>eval/precision</td><td>0.91959</td></tr><tr><td>eval/recall</td><td>0.91658</td></tr><tr><td>eval/runtime</td><td>0.9161</td></tr><tr><td>eval/samples_per_second</td><td>2185.254</td></tr><tr><td>eval/steps_per_second</td><td>68.767</td></tr><tr><td>eval_accuracy</td><td>0.91658</td></tr><tr><td>eval_f1</td><td>0.91735</td></tr><tr><td>eval_loss</td><td>0.03717</td></tr><tr><td>eval_mcc</td><td>0.85455</td></tr><tr><td>eval_precision</td><td>0.91959</td></tr><tr><td>eval_recall</td><td>0.91658</td></tr><tr><td>test/accuracy</td><td>0.91658</td></tr><tr><td>test/f1</td><td>0.91735</td></tr><tr><td>test/loss</td><td>0.03717</td></tr><tr><td>test/mcc</td><td>0.85455</td></tr><tr><td>test/precision</td><td>0.91959</td></tr><tr><td>test/recall</td><td>0.91658</td></tr><tr><td>test/runtime</td><td>1.0119</td></tr><tr><td>test/samples_per_second</td><td>1978.369</td></tr><tr><td>test/steps_per_second</td><td>62.256</td></tr><tr><td>total_flos</td><td>4771529358312960.0</td></tr><tr><td>train/epoch</td><td>10</td></tr><tr><td>train/global_step</td><td>1260</td></tr><tr><td>train/grad_norm</td><td>0.0026</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0004</td></tr><tr><td>train_loss</td><td>0.0312</td></tr><tr><td>train_runtime</td><td>202.7316</td></tr><tr><td>train_samples_per_second</td><td>473.769</td></tr><tr><td>train_steps_per_second</td><td>7.399</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">happy-sweep-25</strong> at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/9j0j85v8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/9j0j85v8</a><br> View project at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250218_030351-9j0j85v8/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 830rrgmy with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.05921821710712821\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 4.634434939662679e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_grad_norm: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 12\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.047477457773195245\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.6"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250218_030729-830rrgmy</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/830rrgmy' target=\"_blank\">fresh-sweep-26</a></strong> to <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/830rrgmy' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/830rrgmy</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Total Steps: 756, Warmup Steps (10%): 75\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_grad_norm' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_train_epochs' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='315' max='744' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [315/744 01:36 < 02:12, 3.23 it/s, Epoch 5/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Mcc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.245700</td>\n","      <td>0.099322</td>\n","      <td>0.753746</td>\n","      <td>0.810229</td>\n","      <td>0.753746</td>\n","      <td>0.757451</td>\n","      <td>0.610964</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.046300</td>\n","      <td>0.032833</td>\n","      <td>0.895604</td>\n","      <td>0.903280</td>\n","      <td>0.895604</td>\n","      <td>0.898136</td>\n","      <td>0.821975</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.021000</td>\n","      <td>0.034628</td>\n","      <td>0.910589</td>\n","      <td>0.918562</td>\n","      <td>0.910589</td>\n","      <td>0.910604</td>\n","      <td>0.841266</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.010900</td>\n","      <td>0.032858</td>\n","      <td>0.908591</td>\n","      <td>0.913334</td>\n","      <td>0.908591</td>\n","      <td>0.909184</td>\n","      <td>0.838883</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.004600</td>\n","      <td>0.043862</td>\n","      <td>0.901598</td>\n","      <td>0.913337</td>\n","      <td>0.901598</td>\n","      <td>0.904692</td>\n","      <td>0.836187</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ Best model saved to /content/drive/MyDrive/RoBERTa_8_Results/fresh-sweep-26/best_model\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▇███▇</td></tr><tr><td>eval/f1</td><td>▁▇███▇</td></tr><tr><td>eval/loss</td><td>█▁▁▁▂▁</td></tr><tr><td>eval/mcc</td><td>▁▇███▇</td></tr><tr><td>eval/precision</td><td>▁▇███▇</td></tr><tr><td>eval/recall</td><td>▁▇███▇</td></tr><tr><td>eval/runtime</td><td>▁▃█▁▂▃</td></tr><tr><td>eval/samples_per_second</td><td>█▆▁█▇▆</td></tr><tr><td>eval/steps_per_second</td><td>█▆▁█▇▆</td></tr><tr><td>eval_accuracy</td><td>▁</td></tr><tr><td>eval_f1</td><td>▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_mcc</td><td>▁</td></tr><tr><td>eval_precision</td><td>▁</td></tr><tr><td>eval_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/mcc</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▅▅▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▅▅▆▆██████</td></tr><tr><td>train/grad_norm</td><td>█▄▂▁▁</td></tr><tr><td>train/learning_rate</td><td>▄█▇▄▁</td></tr><tr><td>train/loss</td><td>█▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.8956</td></tr><tr><td>eval/f1</td><td>0.89814</td></tr><tr><td>eval/loss</td><td>0.03283</td></tr><tr><td>eval/mcc</td><td>0.82198</td></tr><tr><td>eval/precision</td><td>0.90328</td></tr><tr><td>eval/recall</td><td>0.8956</td></tr><tr><td>eval/runtime</td><td>0.9151</td></tr><tr><td>eval/samples_per_second</td><td>2187.809</td></tr><tr><td>eval/steps_per_second</td><td>68.847</td></tr><tr><td>eval_accuracy</td><td>0.8956</td></tr><tr><td>eval_f1</td><td>0.89814</td></tr><tr><td>eval_loss</td><td>0.03283</td></tr><tr><td>eval_mcc</td><td>0.82198</td></tr><tr><td>eval_precision</td><td>0.90328</td></tr><tr><td>eval_recall</td><td>0.8956</td></tr><tr><td>test/accuracy</td><td>0.8956</td></tr><tr><td>test/f1</td><td>0.89814</td></tr><tr><td>test/loss</td><td>0.03283</td></tr><tr><td>test/mcc</td><td>0.82198</td></tr><tr><td>test/precision</td><td>0.90328</td></tr><tr><td>test/recall</td><td>0.8956</td></tr><tr><td>test/runtime</td><td>1.0368</td></tr><tr><td>test/samples_per_second</td><td>1930.964</td></tr><tr><td>test/steps_per_second</td><td>60.765</td></tr><tr><td>total_flos</td><td>2385764679156480.0</td></tr><tr><td>train/epoch</td><td>5</td></tr><tr><td>train/global_step</td><td>315</td></tr><tr><td>train/grad_norm</td><td>0.34409</td></tr><tr><td>train/learning_rate</td><td>3e-05</td></tr><tr><td>train/loss</td><td>0.0046</td></tr><tr><td>train_loss</td><td>0.06569</td></tr><tr><td>train_runtime</td><td>97.2448</td></tr><tr><td>train_samples_per_second</td><td>987.692</td></tr><tr><td>train_steps_per_second</td><td>7.651</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">fresh-sweep-26</strong> at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/830rrgmy' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/830rrgmy</a><br> View project at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250218_030729-830rrgmy/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ybioh8ru with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.05932520932050617\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2.304970853629921e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_grad_norm: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 12\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.04824240804706734\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.6"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250218_030922-ybioh8ru</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/ybioh8ru' target=\"_blank\">effortless-sweep-27</a></strong> to <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/sweeps/4tf3f9z8</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/ybioh8ru' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/ybioh8ru</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Total Steps: 756, Warmup Steps (10%): 75\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_grad_norm' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_train_epochs' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='378' max='744' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [378/744 01:56 < 01:53, 3.22 it/s, Epoch 6/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Mcc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.258000</td>\n","      <td>0.115888</td>\n","      <td>0.768232</td>\n","      <td>0.776938</td>\n","      <td>0.768232</td>\n","      <td>0.746235</td>\n","      <td>0.577242</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.064000</td>\n","      <td>0.040053</td>\n","      <td>0.871129</td>\n","      <td>0.884274</td>\n","      <td>0.871129</td>\n","      <td>0.874404</td>\n","      <td>0.782773</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.025500</td>\n","      <td>0.032985</td>\n","      <td>0.904595</td>\n","      <td>0.907406</td>\n","      <td>0.904595</td>\n","      <td>0.904706</td>\n","      <td>0.829987</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.013900</td>\n","      <td>0.033293</td>\n","      <td>0.908591</td>\n","      <td>0.911519</td>\n","      <td>0.908591</td>\n","      <td>0.907904</td>\n","      <td>0.836891</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.006400</td>\n","      <td>0.034452</td>\n","      <td>0.911089</td>\n","      <td>0.916068</td>\n","      <td>0.911089</td>\n","      <td>0.912438</td>\n","      <td>0.846471</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.003700</td>\n","      <td>0.035948</td>\n","      <td>0.915584</td>\n","      <td>0.915882</td>\n","      <td>0.915584</td>\n","      <td>0.915131</td>\n","      <td>0.850499</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ Best model saved to /content/drive/MyDrive/RoBERTa_8_Results/effortless-sweep-27/best_model\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▆▇███▇</td></tr><tr><td>eval/f1</td><td>▁▆█████</td></tr><tr><td>eval/loss</td><td>█▂▁▁▁▁▁</td></tr><tr><td>eval/mcc</td><td>▁▆▇███▇</td></tr><tr><td>eval/precision</td><td>▁▆█████</td></tr><tr><td>eval/recall</td><td>▁▆▇███▇</td></tr><tr><td>eval/runtime</td><td>▁▁▂▂▂▂█</td></tr><tr><td>eval/samples_per_second</td><td>██▇▇▇▇▁</td></tr><tr><td>eval/steps_per_second</td><td>██▇▇▇▇▁</td></tr><tr><td>eval_accuracy</td><td>▁</td></tr><tr><td>eval_f1</td><td>▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_mcc</td><td>▁</td></tr><tr><td>eval_precision</td><td>▁</td></tr><tr><td>eval_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/mcc</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▄▄▅▅▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▄▄▅▅▇▇██████</td></tr><tr><td>train/grad_norm</td><td>▅▆█▃▁▂</td></tr><tr><td>train/learning_rate</td><td>▆█▇▅▃▁</td></tr><tr><td>train/loss</td><td>█▃▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.9046</td></tr><tr><td>eval/f1</td><td>0.90471</td></tr><tr><td>eval/loss</td><td>0.03299</td></tr><tr><td>eval/mcc</td><td>0.82999</td></tr><tr><td>eval/precision</td><td>0.90741</td></tr><tr><td>eval/recall</td><td>0.9046</td></tr><tr><td>eval/runtime</td><td>1.0183</td></tr><tr><td>eval/samples_per_second</td><td>1966.026</td></tr><tr><td>eval/steps_per_second</td><td>61.868</td></tr><tr><td>eval_accuracy</td><td>0.9046</td></tr><tr><td>eval_f1</td><td>0.90471</td></tr><tr><td>eval_loss</td><td>0.03299</td></tr><tr><td>eval_mcc</td><td>0.82999</td></tr><tr><td>eval_precision</td><td>0.90741</td></tr><tr><td>eval_recall</td><td>0.9046</td></tr><tr><td>test/accuracy</td><td>0.9046</td></tr><tr><td>test/f1</td><td>0.90471</td></tr><tr><td>test/loss</td><td>0.03299</td></tr><tr><td>test/mcc</td><td>0.82999</td></tr><tr><td>test/precision</td><td>0.90741</td></tr><tr><td>test/recall</td><td>0.9046</td></tr><tr><td>test/runtime</td><td>1.132</td></tr><tr><td>test/samples_per_second</td><td>1768.564</td></tr><tr><td>test/steps_per_second</td><td>55.654</td></tr><tr><td>total_flos</td><td>2862917614987776.0</td></tr><tr><td>train/epoch</td><td>6</td></tr><tr><td>train/global_step</td><td>378</td></tr><tr><td>train/grad_norm</td><td>0.65589</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.0037</td></tr><tr><td>train_loss</td><td>0.06191</td></tr><tr><td>train_runtime</td><td>116.9458</td></tr><tr><td>train_samples_per_second</td><td>821.303</td></tr><tr><td>train_steps_per_second</td><td>6.362</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">effortless-sweep-27</strong> at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/ybioh8ru' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8/runs/ybioh8ru</a><br> View project at: <a href='https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8' target=\"_blank\">https://wandb.ai/abdulrahim-alhaizaey/RoBERTa_8</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250218_030922-ybioh8ru/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Exiting.\n"]}]}]}